{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "- https://wikidocs.net/24996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/spa-eng.zip'\n",
    "filename = 'spa-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125446"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines= pd.read_csv('spa.txt', names=['src', 'tar', 'what'], sep='\\t') \n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63698</th>\n",
       "      <td>Can't you see we're very busy?</td>\n",
       "      <td>¿No ves que estamos muy ocupados?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40050</th>\n",
       "      <td>These scissors cut well.</td>\n",
       "      <td>Estas tijeras cortan bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77653</th>\n",
       "      <td>It is worth visiting that museum.</td>\n",
       "      <td>Vale la pena visitar ese museo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>Are you coming?</td>\n",
       "      <td>¿Vienes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17402</th>\n",
       "      <td>I couldn't bear it.</td>\n",
       "      <td>No pude soportarlo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93906</th>\n",
       "      <td>On July tenth, the veto was announced.</td>\n",
       "      <td>El diez de julio, el veto fue anunciado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43448</th>\n",
       "      <td>I'm sorry I bothered you.</td>\n",
       "      <td>Siento haberte importunado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11982</th>\n",
       "      <td>My house is tiny.</td>\n",
       "      <td>Mi casa es minúscula.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40293</th>\n",
       "      <td>Tom died in an accident.</td>\n",
       "      <td>Tom murió en un accidente.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31829</th>\n",
       "      <td>We continued chatting.</td>\n",
       "      <td>Seguimos hablando.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          src  \\\n",
       "63698          Can't you see we're very busy?   \n",
       "40050                These scissors cut well.   \n",
       "77653       It is worth visiting that museum.   \n",
       "5916                          Are you coming?   \n",
       "17402                     I couldn't bear it.   \n",
       "93906  On July tenth, the veto was announced.   \n",
       "43448               I'm sorry I bothered you.   \n",
       "11982                       My house is tiny.   \n",
       "40293                Tom died in an accident.   \n",
       "31829                  We continued chatting.   \n",
       "\n",
       "                                            tar  \n",
       "63698         ¿No ves que estamos muy ocupados?  \n",
       "40050                Estas tijeras cortan bien.  \n",
       "77653           Vale la pena visitar ese museo.  \n",
       "5916                                   ¿Vienes?  \n",
       "17402                       No pude soportarlo.  \n",
       "93906  El diez de julio, el veto fue anunciado.  \n",
       "43448               Siento haberte importunado.  \n",
       "11982                     Mi casa es minúscula.  \n",
       "40293                Tom murió en un accidente.  \n",
       "31829                        Seguimos hablando.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:100000] # 10만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51819</th>\n",
       "      <td>I should have left earlier.</td>\n",
       "      <td>\\t Debería haberme ido antes. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89821</th>\n",
       "      <td>Do you know if Tom has already eaten?</td>\n",
       "      <td>\\t ¿Sabe usted si Tom ya ha comido? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17664</th>\n",
       "      <td>I like watching TV.</td>\n",
       "      <td>\\t Me gusta ver televisión. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32795</th>\n",
       "      <td>Do you speak Esperanto?</td>\n",
       "      <td>\\t ¿Hablas esperanto? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78882</th>\n",
       "      <td>Tom doesn't like classical music.</td>\n",
       "      <td>\\t A Tom no le gusta la música clásica. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44060</th>\n",
       "      <td>She doesn't need to work.</td>\n",
       "      <td>\\t Ella no tiene que trabajar. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36697</th>\n",
       "      <td>Where does that bus go?</td>\n",
       "      <td>\\t ¿Hacia dónde va el colectivo? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23924</th>\n",
       "      <td>Where's your mother?</td>\n",
       "      <td>\\t ¿Dónde está tu madre? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63087</th>\n",
       "      <td>We've been talking about you.</td>\n",
       "      <td>\\t Hemos estado hablando sobre ti. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65333</th>\n",
       "      <td>I've lived here my whole life.</td>\n",
       "      <td>\\t He vivido aquí mi vida entera. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         src  \\\n",
       "51819            I should have left earlier.   \n",
       "89821  Do you know if Tom has already eaten?   \n",
       "17664                    I like watching TV.   \n",
       "32795                Do you speak Esperanto?   \n",
       "78882      Tom doesn't like classical music.   \n",
       "44060              She doesn't need to work.   \n",
       "36697                Where does that bus go?   \n",
       "23924                   Where's your mother?   \n",
       "63087          We've been talking about you.   \n",
       "65333         I've lived here my whole life.   \n",
       "\n",
       "                                              tar  \n",
       "51819            \\t Debería haberme ido antes. \\n  \n",
       "89821      \\t ¿Sabe usted si Tom ya ha comido? \\n  \n",
       "17664              \\t Me gusta ver televisión. \\n  \n",
       "32795                    \\t ¿Hablas esperanto? \\n  \n",
       "78882  \\t A Tom no le gusta la música clásica. \\n  \n",
       "44060           \\t Ella no tiene que trabajar. \\n  \n",
       "36697         \\t ¿Hacia dónde va el colectivo? \\n  \n",
       "23924                 \\t ¿Dónde está tu madre? \\n  \n",
       "63087       \\t Hemos estado hablando sobre ti. \\n  \n",
       "65333        \\t He vivido aquí mi vida entera. \\n  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장의 시작과 끝을 나타내는 토큰 설정\n",
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 글자 집합 구축\n",
    "src_vocab=set()\n",
    "for line in lines.src: # 1줄씩\n",
    "    for char in line: # 1글자씩\n",
    "        src_vocab.add(char) #set에는 add를 통해 자료 추가\n",
    "#training set에서 나타난 알파벳들을 저장\n",
    "\n",
    "# 스페인어 글자 집합 구축\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 글자 집합: 87\n",
      "스페인어 글자 집합: 105\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(\"영어 글자 집합:\", src_vocab_size)\n",
    "print(\"스페인어 글자 집합:\", tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '/': 10, '0': 11, '1': 12, '2': 13, '3': 14, '4': 15, '5': 16, '6': 17, '7': 18, '8': 19, '9': 20, ':': 21, ';': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '\\xa0': 76, '°': 77, 'á': 78, 'ã': 79, 'è': 80, 'é': 81, 'ö': 82, '‘': 83, '’': 84, '₂': 85, '€': 86}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, \"'\": 8, '(': 9, ')': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '?': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, 'a': 55, 'b': 56, 'c': 57, 'd': 58, 'e': 59, 'f': 60, 'g': 61, 'h': 62, 'i': 63, 'j': 64, 'k': 65, 'l': 66, 'm': 67, 'n': 68, 'o': 69, 'p': 70, 'q': 71, 'r': 72, 's': 73, 't': 74, 'u': 75, 'v': 76, 'w': 77, 'x': 78, 'y': 79, 'z': 80, '¡': 81, '«': 82, '°': 83, 'º': 84, '»': 85, '¿': 86, 'Á': 87, 'É': 88, 'Ó': 89, 'Ú': 90, 'á': 91, 'è': 92, 'é': 93, 'í': 94, 'ñ': 95, 'ó': 96, 'ö': 97, 'ú': 98, 'ü': 99, 'ś': 100, 'с': 101, '\\u200b': 102, '—': 103, '€': 104}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)\n",
    "#각 알파벳들에 index 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정수 인코딩\n",
    "- 입력 데이터와 출력 데이터 모두를 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 9], [30, 64, 9], [30, 64, 9], [30, 64, 9], [31, 58, 9]]\n",
      "0    Go.\n",
      "1    Go.\n",
      "2    Go.\n",
      "3    Go.\n",
      "4    Hi.\n",
      "Name: src, dtype: object\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])\n",
    "print(lines.src[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 50, 59, 14, 3, 2], [1, 3, 50, 59, 74, 59, 14, 3, 2], [1, 3, 50, 55, 79, 55, 14, 3, 2], [1, 3, 50, 91, 79, 55, 73, 59, 14, 3, 2], [1, 3, 36, 69, 66, 55, 14, 3, 2]]\n",
      "0        \\t Ve. \\n\n",
      "1      \\t Vete. \\n\n",
      "2      \\t Vaya. \\n\n",
      "3    \\t Váyase. \\n\n",
      "4      \\t Hola. \\n\n",
      "Name: tar, dtype: object\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])\n",
    "print(lines.tar[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 50, 59, 14, 3, 2], [3, 50, 59, 74, 59, 14, 3, 2], [3, 50, 55, 79, 55, 14, 3, 2], [3, 50, 91, 79, 55, 73, 59, 14, 3, 2], [3, 36, 69, 66, 55, 14, 3, 2]]\n",
      "0         Ve. \n",
      "1       Vete. \n",
      "2       Vaya. \n",
      "3     Váyase. \n",
      "4       Hola. \n",
      "Name: tar, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#번역 결과에 시작과 끝을 나타내는 토큰은 필요하지 않다.\n",
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])\n",
    "print(lines.tar[:5].apply(lambda x: re.sub('\\t','',x)).apply(lambda x: re.sub('\\n','', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어의 최대길이: 41\n",
      "스페인어의 최대길이: 96\n"
     ]
    }
   ],
   "source": [
    "#패딩값을 주기 위해 최대 길이를 조절\n",
    "#영어의 최대 길이와 스페인어의 최대 길이를 맞춰줄 필요는 없다. 영어는 영어끼리, 스페인어는 스페인어끼리\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print('영어의 최대길이:', max_src_len)\n",
    "print('스페인어의 최대길이:', max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 값에 대하여 one_hot 인코딩을 수행\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "#인코더 내부 상태를 디코더로 넘겨주어야 하기 때문에 return_state=True/ 인코더에 입력을 넣으면 내부 상태를 리턴\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태(h)와 셀(c) 상태. 은닉상태와 셀 상태 두가지를 전달\n",
    "#encoder_state에 은닉상태와 셀 상태 두가지를 저장하고, 이를 디코더에 전달하여 두 가지 상태 모두를 디코더로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 마지막 은닉 상태, 셀 상태로. 이에 따라 initial_state를 encoder_state로\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "#val_accuracy가 감소하게 되면 자동으로 epoch를 멈추는 earlystopping 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.5985 - accuracy: 0.8276 - val_loss: 0.6783 - val_accuracy: 0.7943\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.3926 - accuracy: 0.8810 - val_loss: 0.5628 - val_accuracy: 0.8307\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 24s 20ms/step - loss: 0.3345 - accuracy: 0.8992 - val_loss: 0.5112 - val_accuracy: 0.8464\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 24s 20ms/step - loss: 0.3040 - accuracy: 0.9084 - val_loss: 0.4795 - val_accuracy: 0.8559\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2844 - accuracy: 0.9140 - val_loss: 0.4604 - val_accuracy: 0.8614\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2705 - accuracy: 0.9181 - val_loss: 0.4486 - val_accuracy: 0.8644\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2598 - accuracy: 0.9213 - val_loss: 0.4396 - val_accuracy: 0.8674\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2512 - accuracy: 0.9238 - val_loss: 0.4324 - val_accuracy: 0.8698\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2441 - accuracy: 0.9258 - val_loss: 0.4264 - val_accuracy: 0.8718\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2381 - accuracy: 0.9276 - val_loss: 0.4218 - val_accuracy: 0.8734\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2327 - accuracy: 0.9292 - val_loss: 0.4192 - val_accuracy: 0.8743\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2280 - accuracy: 0.9305 - val_loss: 0.4158 - val_accuracy: 0.8752\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2238 - accuracy: 0.9317 - val_loss: 0.4126 - val_accuracy: 0.8760\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2199 - accuracy: 0.9329 - val_loss: 0.4131 - val_accuracy: 0.8764\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2162 - accuracy: 0.9339 - val_loss: 0.4094 - val_accuracy: 0.8779\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.2128 - accuracy: 0.9350 - val_loss: 0.4103 - val_accuracy: 0.8776\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2097 - accuracy: 0.9359 - val_loss: 0.4104 - val_accuracy: 0.8779\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2067 - accuracy: 0.9368 - val_loss: 0.4087 - val_accuracy: 0.8788\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2039 - accuracy: 0.9376 - val_loss: 0.4084 - val_accuracy: 0.8790\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.2014 - accuracy: 0.9384 - val_loss: 0.4089 - val_accuracy: 0.8789\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1989 - accuracy: 0.9391 - val_loss: 0.4086 - val_accuracy: 0.8792\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1966 - accuracy: 0.9398 - val_loss: 0.4096 - val_accuracy: 0.8796\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1944 - accuracy: 0.9404 - val_loss: 0.4095 - val_accuracy: 0.8798\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1923 - accuracy: 0.9410 - val_loss: 0.4096 - val_accuracy: 0.8796\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1903 - accuracy: 0.9417 - val_loss: 0.4098 - val_accuracy: 0.8801\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1885 - accuracy: 0.9421 - val_loss: 0.4116 - val_accuracy: 0.8797\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.1867 - accuracy: 0.9427 - val_loss: 0.4112 - val_accuracy: 0.8801\n",
      "Epoch 28/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1850 - accuracy: 0.9432 - val_loss: 0.4132 - val_accuracy: 0.8800\n",
      "Epoch 29/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1834 - accuracy: 0.9437 - val_loss: 0.4138 - val_accuracy: 0.8798\n",
      "Epoch 30/50\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 0.1818 - accuracy: 0.9442 - val_loss: 0.4146 - val_accuracy: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18cd659a278>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장:  Ve. \n",
      "번역기가 번역한 문장:  Vete. \n",
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장:  Vete. \n",
      "번역기가 번역한 문장:  Vete. \n",
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장:  Vaya. \n",
      "번역기가 번역한 문장:  Vete. \n",
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장:  Váyase. \n",
      "번역기가 번역한 문장:  Vete. \n",
      "-----------------------------------\n",
      "입력 문장: Hi.\n",
      "정답 문장:  Hola. \n",
      "번역기가 번역한 문장:  Disculpa. \n",
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  ¡Corre! \n",
      "번역기가 번역한 문장:  ¡Colvido! \n",
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  ¡Corran! \n",
      "번역기가 번역한 문장:  ¡Colvido! \n",
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  ¡Corra! \n",
      "번역기가 번역한 문장:  ¡Colvido! \n",
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  ¡Corred! \n",
      "번역기가 번역한 문장:  ¡Colvido! \n",
      "-----------------------------------\n",
      "입력 문장: Run.\n",
      "정답 문장:  Corred. \n",
      "번역기가 번역한 문장:  Conseguelo. \n",
      "-----------------------------------\n",
      "입력 문장: Who?\n",
      "정답 문장:  ¿Quién? \n",
      "번역기가 번역한 문장:  ¿A quién confiese? \n",
      "-----------------------------------\n",
      "입력 문장: Wow!\n",
      "정답 문장:  ¡Órale! \n",
      "번역기가 번역한 문장:  ¡Para! \n",
      "-----------------------------------\n",
      "입력 문장: Fire!\n",
      "정답 문장:  ¡Fuego! \n",
      "번역기가 번역한 문장:  ¡Hace un poco! \n",
      "-----------------------------------\n",
      "입력 문장: Fire!\n",
      "정답 문장:  ¡Incendio! \n",
      "번역기가 번역한 문장:  ¡Hace un poco! \n",
      "-----------------------------------\n",
      "입력 문장: Fire!\n",
      "정답 문장:  ¡Disparad! \n",
      "번역기가 번역한 문장:  ¡Hace un poco! \n",
      "-----------------------------------\n",
      "입력 문장: Help!\n",
      "정답 문장:  ¡Ayuda! \n",
      "번역기가 번역한 문장:  ¡Aticado! \n",
      "-----------------------------------\n",
      "입력 문장: Help!\n",
      "정답 문장:  ¡Socorro! ¡Auxilio! \n",
      "번역기가 번역한 문장:  ¡Aticado! \n",
      "-----------------------------------\n",
      "입력 문장: Help!\n",
      "정답 문장:  ¡Auxilio! \n",
      "번역기가 번역한 문장:  ¡Aticado! \n",
      "-----------------------------------\n",
      "입력 문장: Jump!\n",
      "정답 문장:  ¡Salta! \n",
      "번역기가 번역한 문장:  ¡Para de él! \n",
      "-----------------------------------\n",
      "입력 문장: Jump.\n",
      "정답 문장:  Salte. \n",
      "번역기가 번역한 문장:  Suéltame. \n",
      "-----------------------------------\n",
      "입력 문장: Stop!\n",
      "정답 문장:  ¡Parad! \n",
      "번역기가 번역한 문장:  ¡Pare! \n",
      "-----------------------------------\n",
      "입력 문장: Stop!\n",
      "정답 문장:  ¡Para! \n",
      "번역기가 번역한 문장:  ¡Pare! \n",
      "-----------------------------------\n",
      "입력 문장: Stop!\n",
      "정답 문장:  ¡Pare! \n",
      "번역기가 번역한 문장:  ¡Pare! \n",
      "-----------------------------------\n",
      "입력 문장: Wait!\n",
      "정답 문장:  ¡Espera! \n",
      "번역기가 번역한 문장:  ¡Acaba! \n",
      "-----------------------------------\n",
      "입력 문장: Wait.\n",
      "정답 문장:  Esperen. \n",
      "번역기가 번역한 문장:  Espera. \n",
      "-----------------------------------\n",
      "입력 문장: Go on.\n",
      "정답 문장:  Continúa. \n",
      "번역기가 번역한 문장:  Vete a casa. \n",
      "-----------------------------------\n",
      "입력 문장: Go on.\n",
      "정답 문장:  Continúe. \n",
      "번역기가 번역한 문장:  Vete a casa. \n",
      "-----------------------------------\n",
      "입력 문장: Hello!\n",
      "정답 문장:  Hola. \n",
      "번역기가 번역한 문장:  Hazto. \n",
      "-----------------------------------\n",
      "입력 문장: Hurry!\n",
      "정답 문장:  ¡Date prisa! \n",
      "번역기가 번역한 문장:  ¡Date usted! \n",
      "-----------------------------------\n",
      "입력 문장: Hurry!\n",
      "정답 문장:  ¡Daos prisa! \n",
      "번역기가 번역한 문장:  ¡Date usted! \n",
      "-----------------------------------\n",
      "입력 문장: Hurry!\n",
      "정답 문장:  Dese prisa. \n",
      "번역기가 번역한 문장:  ¡Date usted! \n",
      "-----------------------------------\n",
      "입력 문장: I hid.\n",
      "정답 문장:  Me oculté. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I hid.\n",
      "정답 문장:  Me escondí. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I hid.\n",
      "정답 문장:  Me ocultaba. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I hid.\n",
      "정답 문장:  Me escondía. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I ran.\n",
      "정답 문장:  Corrí. \n",
      "번역기가 번역한 문장:  Conduce. \n",
      "-----------------------------------\n",
      "입력 문장: I ran.\n",
      "정답 문장:  Corría. \n",
      "번역기가 번역한 문장:  Conduce. \n",
      "-----------------------------------\n",
      "입력 문장: I try.\n",
      "정답 문장:  Lo intento. \n",
      "번역기가 번역한 문장:  Yo estoy de acuerdo. \n",
      "-----------------------------------\n",
      "입력 문장: I won!\n",
      "정답 문장:  ¡He ganado! \n",
      "번역기가 번역한 문장:  ¡Haz! \n",
      "-----------------------------------\n",
      "입력 문장: Oh no!\n",
      "정답 문장:  ¡Oh, no! \n",
      "번역기가 번역한 문장:  ¡Para! \n",
      "-----------------------------------\n",
      "입력 문장: Relax.\n",
      "정답 문장:  Tomátelo con soda. \n",
      "번역기가 번역한 문장:  Sé sensible. \n",
      "-----------------------------------\n",
      "입력 문장: Shoot!\n",
      "정답 문장:  ¡Fuego! \n",
      "번역기가 번역한 문장:  ¡Disparad! \n",
      "-----------------------------------\n",
      "입력 문장: Shoot!\n",
      "정답 문장:  ¡Disparad! \n",
      "번역기가 번역한 문장:  ¡Disparad! \n",
      "-----------------------------------\n",
      "입력 문장: Shoot!\n",
      "정답 문장:  ¡Disparen! \n",
      "번역기가 번역한 문장:  ¡Disparad! \n",
      "-----------------------------------\n",
      "입력 문장: Shoot!\n",
      "정답 문장:  ¡Dispara! \n",
      "번역기가 번역한 문장:  ¡Disparad! \n",
      "-----------------------------------\n",
      "입력 문장: Shoot!\n",
      "정답 문장:  ¡Dispará! \n",
      "번역기가 번역한 문장:  ¡Disparad! \n",
      "-----------------------------------\n",
      "입력 문장: Shoot!\n",
      "정답 문장:  ¡Dispare! \n",
      "번역기가 번역한 문장:  ¡Disparad! \n",
      "-----------------------------------\n",
      "입력 문장: Smile.\n",
      "정답 문장:  Sonríe. \n",
      "번역기가 번역한 문장:  Presir. \n",
      "-----------------------------------\n",
      "입력 문장: Attack!\n",
      "정답 문장:  ¡Al ataque! \n",
      "번역기가 번역한 문장:  ¡Ataca! \n",
      "-----------------------------------\n",
      "입력 문장: Attack!\n",
      "정답 문장:  ¡Atacad! \n",
      "번역기가 번역한 문장:  ¡Ataca! \n",
      "-----------------------------------\n",
      "입력 문장: Attack!\n",
      "정답 문장:  ¡Ataque! \n",
      "번역기가 번역한 문장:  ¡Ataca! \n",
      "-----------------------------------\n",
      "입력 문장: Attack!\n",
      "정답 문장:  ¡Ataquen! \n",
      "번역기가 번역한 문장:  ¡Ataca! \n",
      "-----------------------------------\n",
      "입력 문장: Attack!\n",
      "정답 문장:  ¡Ataca! \n",
      "번역기가 번역한 문장:  ¡Ataca! \n",
      "-----------------------------------\n",
      "입력 문장: Get up.\n",
      "정답 문장:  Levanta. \n",
      "번역기가 번역한 문장:  Salid. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Ve ahora mismo. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Id ahora mismo. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Vaya ahora mismo. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Vayan ahora mismo. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Ve ya. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Id ya. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Vaya ya. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Go now.\n",
      "정답 문장:  Vayan ya. \n",
      "번역기가 번역한 문장:  Vaya ahora. \n",
      "-----------------------------------\n",
      "입력 문장: Got it!\n",
      "정답 문장:  ¡Lo tengo! \n",
      "번역기가 번역한 문장:  ¡Lo te conoce! \n",
      "-----------------------------------\n",
      "입력 문장: Got it?\n",
      "정답 문장:  ¿Lo pillas? \n",
      "번역기가 번역한 문장:  ¿Lo encontraste? \n",
      "-----------------------------------\n",
      "입력 문장: Got it?\n",
      "정답 문장:  ¿Entendiste? \n",
      "번역기가 번역한 문장:  ¿Lo encontraste? \n",
      "-----------------------------------\n",
      "입력 문장: He ran.\n",
      "정답 문장:  Él corrió. \n",
      "번역기가 번역한 문장:  Él corrió. \n",
      "-----------------------------------\n",
      "입력 문장: Hop in.\n",
      "정답 문장:  Métete adentro. \n",
      "번역기가 번역한 문장:  Sostene. \n",
      "-----------------------------------\n",
      "입력 문장: Hug me.\n",
      "정답 문장:  Abrázame. \n",
      "번역기가 번역한 문장:  Date prisa. \n",
      "-----------------------------------\n",
      "입력 문장: I care.\n",
      "정답 문장:  Me preocupo. \n",
      "번역기가 번역한 문장:  Yo visto. \n",
      "-----------------------------------\n",
      "입력 문장: I fell.\n",
      "정답 문장:  Me caí. \n",
      "번역기가 번역한 문장:  Me encantan los perros. \n",
      "-----------------------------------\n",
      "입력 문장: I fled.\n",
      "정답 문장:  Huí. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I fled.\n",
      "정답 문장:  Me escapé. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I fled.\n",
      "정답 문장:  Huía. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I fled.\n",
      "정답 문장:  Me escapaba. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I know.\n",
      "정답 문장:  Yo lo sé. \n",
      "번역기가 번역한 문장:  Yo lo sé. \n",
      "-----------------------------------\n",
      "입력 문장: I left.\n",
      "정답 문장:  Salí. \n",
      "번역기가 번역한 문장:  Me encanta. \n",
      "-----------------------------------\n",
      "입력 문장: I lied.\n",
      "정답 문장:  Mentí. \n",
      "번역기가 번역한 문장:  Me volví. \n",
      "-----------------------------------\n",
      "입력 문장: I lost.\n",
      "정답 문장:  Perdí. \n",
      "번역기가 번역한 문장:  Yo como mejor. \n",
      "-----------------------------------\n",
      "입력 문장: I quit.\n",
      "정답 문장:  Dimito. \n",
      "번역기가 번역한 문장:  Despierta. \n",
      "-----------------------------------\n",
      "입력 문장: I quit.\n",
      "정답 문장:  Renuncié. \n",
      "번역기가 번역한 문장:  Despierta. \n",
      "-----------------------------------\n",
      "입력 문장: I quit.\n",
      "정답 문장:  Lo dejo. \n",
      "번역기가 번역한 문장:  Despierta. \n",
      "-----------------------------------\n",
      "입력 문장: I sang.\n",
      "정답 문장:  Canté. \n",
      "번역기가 번역한 문장:  Confío en él. \n",
      "-----------------------------------\n",
      "입력 문장: I wept.\n",
      "정답 문장:  Lloré. \n",
      "번역기가 번역한 문장:  Lo sabía. \n",
      "-----------------------------------\n",
      "입력 문장: I wept.\n",
      "정답 문장:  Lloraba. \n",
      "번역기가 번역한 문장:  Lo sabía. \n",
      "-----------------------------------\n",
      "입력 문장: I work.\n",
      "정답 문장:  Estoy trabajando. \n",
      "번역기가 번역한 문장:  Yo estoy de acuerdo. \n",
      "-----------------------------------\n",
      "입력 문장: I'm 19.\n",
      "정답 문장:  Tengo diecinueve. \n",
      "번역기가 번역한 문장:  Soy tuyo. \n",
      "-----------------------------------\n",
      "입력 문장: I'm up.\n",
      "정답 문장:  Estoy levantado. \n",
      "번역기가 번역한 문장:  Estoy listo. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Listen.\n",
      "정답 문장:  Escucha. \n",
      "번역기가 번역한 문장:  Escuchen. \n",
      "-----------------------------------\n",
      "입력 문장: Listen.\n",
      "정답 문장:  Escuche. \n",
      "번역기가 번역한 문장:  Escuchen. \n",
      "-----------------------------------\n",
      "입력 문장: Listen.\n",
      "정답 문장:  Escuchen. \n",
      "번역기가 번역한 문장:  Escuchen. \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡No puede ser! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  De ninguna manera. \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡De ninguna manera! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡Imposible! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡De ningún modo! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡De eso nada! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡Ni cagando! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡Mangos! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡Minga! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n",
      "-----------------------------------\n",
      "입력 문장: No way!\n",
      "정답 문장:  ¡Ni en pedo! \n",
      "번역기가 번역한 문장:  ¡Por favor! \n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100): # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 번역된 결과는 틀린 답을 내긴 했으나, 문장의 구성요소를 갖추고 있고, 그 자체로 의미를 지닌 문장임\n",
    "---\n",
    "- 입력 문장: Stop! / 정답 문장:  ¡Pare! / 번역기가 번역한 문장:  ¡Pare!\n",
    "- 입력 문장: Stop! / 정답 문장:  ¡Para! / 번역기가 번역한 문장:  ¡Pare! \n",
    "- 입력 문장: Wait. / 정답 문장:  Esperen. / 번역기가 번역한 문장:  Espera.  \n",
    "-- 하나의 영어 단어, 문장에는 하나의 스페인어 답이 배정된다.  \n",
    "-- 스페인어는 인칭 변화에 따라 동사의 형태가 변화하는 반면, 영어의 경우는 변화가 없기에 발생하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'spa-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000\n",
    "#샘플 사용량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "교사 강요 (Teacher Forcing)을 위해 훈련에 사용할 디코더의 입력 시퀀스와\n",
    "실제 값에 해당하는 출력 시퀀스를 따로 분리하여 저장.\n",
    "입력 시퀀스에는 <SOS>를, 출력 시퀀스에는 <EOS>\n",
    "'''\n",
    "\n",
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"spa.txt\", \"r\", encoding='UTF8') as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "[['<sos>', 've', '.'], ['<sos>', 'vete', '.'], ['<sos>', 'vaya', '.'], ['<sos>', 'vayase', '.'], ['<sos>', 'hola', '.']]\n",
      "[['ve', '.', '<eos>'], ['vete', '.', '<eos>'], ['vaya', '.', '<eos>'], ['vayase', '.', '<eos>'], ['hola', '.', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_spa_in, sents_spa_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_spa_in[:5])\n",
    "print(sents_spa_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<sos>', 've', '.'],\n",
       " ['<sos>', 'vete', '.'],\n",
       " ['<sos>', 'vaya', '.'],\n",
       " ['<sos>', 'vayase', '.'],\n",
       " ['<sos>', 'hola', '.'],\n",
       " ['<sos>', 'corre', '!'],\n",
       " ['<sos>', 'corran', '!'],\n",
       " ['<sos>', 'corra', '!'],\n",
       " ['<sos>', 'corred', '!'],\n",
       " ['<sos>', 'corred', '.'],\n",
       " ['<sos>', 'quien', '?'],\n",
       " ['<sos>', 'orale', '!'],\n",
       " ['<sos>', 'fuego', '!'],\n",
       " ['<sos>', 'incendio', '!'],\n",
       " ['<sos>', 'disparad', '!'],\n",
       " ['<sos>', 'ayuda', '!'],\n",
       " ['<sos>', 'socorro', '!', 'auxilio', '!'],\n",
       " ['<sos>', 'auxilio', '!'],\n",
       " ['<sos>', 'salta', '!'],\n",
       " ['<sos>', 'salte', '.'],\n",
       " ['<sos>', 'parad', '!'],\n",
       " ['<sos>', 'para', '!'],\n",
       " ['<sos>', 'pare', '!'],\n",
       " ['<sos>', 'espera', '!'],\n",
       " ['<sos>', 'esperen', '.'],\n",
       " ['<sos>', 'continua', '.'],\n",
       " ['<sos>', 'continue', '.'],\n",
       " ['<sos>', 'hola', '.'],\n",
       " ['<sos>', 'date', 'prisa', '!'],\n",
       " ['<sos>', 'daos', 'prisa', '!'],\n",
       " ['<sos>', 'dese', 'prisa', '.'],\n",
       " ['<sos>', 'me', 'oculte', '.'],\n",
       " ['<sos>', 'me', 'escondi', '.'],\n",
       " ['<sos>', 'me', 'ocultaba', '.'],\n",
       " ['<sos>', 'me', 'escondia', '.'],\n",
       " ['<sos>', 'corri', '.'],\n",
       " ['<sos>', 'corria', '.'],\n",
       " ['<sos>', 'lo', 'intento', '.'],\n",
       " ['<sos>', 'he', 'ganado', '!'],\n",
       " ['<sos>', 'oh', 'no', '!'],\n",
       " ['<sos>', 'tomatelo', 'con', 'soda', '.'],\n",
       " ['<sos>', 'fuego', '!'],\n",
       " ['<sos>', 'disparad', '!'],\n",
       " ['<sos>', 'disparen', '!'],\n",
       " ['<sos>', 'dispara', '!'],\n",
       " ['<sos>', 'dispara', '!'],\n",
       " ['<sos>', 'dispare', '!'],\n",
       " ['<sos>', 'sonrie', '.'],\n",
       " ['<sos>', 'al', 'ataque', '!'],\n",
       " ['<sos>', 'atacad', '!'],\n",
       " ['<sos>', 'ataque', '!'],\n",
       " ['<sos>', 'ataquen', '!'],\n",
       " ['<sos>', 'ataca', '!'],\n",
       " ['<sos>', 'levanta', '.'],\n",
       " ['<sos>', 've', 'ahora', 'mismo', '.'],\n",
       " ['<sos>', 'id', 'ahora', 'mismo', '.'],\n",
       " ['<sos>', 'vaya', 'ahora', 'mismo', '.'],\n",
       " ['<sos>', 'vayan', 'ahora', 'mismo', '.'],\n",
       " ['<sos>', 've', 'ya', '.'],\n",
       " ['<sos>', 'id', 'ya', '.'],\n",
       " ['<sos>', 'vaya', 'ya', '.'],\n",
       " ['<sos>', 'vayan', 'ya', '.'],\n",
       " ['<sos>', 'lo', 'tengo', '!'],\n",
       " ['<sos>', 'lo', 'pillas', '?'],\n",
       " ['<sos>', 'entendiste', '?'],\n",
       " ['<sos>', 'el', 'corrio', '.'],\n",
       " ['<sos>', 'metete', 'adentro', '.'],\n",
       " ['<sos>', 'abrazame', '.'],\n",
       " ['<sos>', 'me', 'preocupo', '.'],\n",
       " ['<sos>', 'me', 'cai', '.'],\n",
       " ['<sos>', 'hui', '.'],\n",
       " ['<sos>', 'me', 'escape', '.'],\n",
       " ['<sos>', 'huia', '.'],\n",
       " ['<sos>', 'me', 'escapaba', '.'],\n",
       " ['<sos>', 'yo', 'lo', 'se', '.'],\n",
       " ['<sos>', 'sali', '.'],\n",
       " ['<sos>', 'menti', '.'],\n",
       " ['<sos>', 'perdi', '.'],\n",
       " ['<sos>', 'dimito', '.'],\n",
       " ['<sos>', 'renuncie', '.'],\n",
       " ['<sos>', 'lo', 'dejo', '.'],\n",
       " ['<sos>', 'cante', '.'],\n",
       " ['<sos>', 'llore', '.'],\n",
       " ['<sos>', 'lloraba', '.'],\n",
       " ['<sos>', 'estoy', 'trabajando', '.'],\n",
       " ['<sos>', 'tengo', 'diecinueve', '.'],\n",
       " ['<sos>', 'estoy', 'levantado', '.'],\n",
       " ['<sos>', 'escucha', '.'],\n",
       " ['<sos>', 'escuche', '.'],\n",
       " ['<sos>', 'escuchen', '.'],\n",
       " ['<sos>', 'no', 'puede', 'ser', '!'],\n",
       " ['<sos>', 'de', 'ninguna', 'manera', '.'],\n",
       " ['<sos>', 'de', 'ninguna', 'manera', '!'],\n",
       " ['<sos>', 'imposible', '!'],\n",
       " ['<sos>', 'de', 'ningun', 'modo', '!'],\n",
       " ['<sos>', 'de', 'eso', 'nada', '!'],\n",
       " ['<sos>', 'ni', 'cagando', '!'],\n",
       " ['<sos>', 'mangos', '!'],\n",
       " ['<sos>', 'minga', '!'],\n",
       " ['<sos>', 'ni', 'en', 'pedo', '!']]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_spa_in[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_spa = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_in)\n",
    "tokenizer_spa.fit_on_texts(sents_spa_out)\n",
    "\n",
    "decoder_input = tokenizer_spa.texts_to_sequences(sents_spa_in)\n",
    "decoder_target = tokenizer_spa.texts_to_sequences(sents_spa_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 302, 1],\n",
       " [2, 1052, 1],\n",
       " [2, 479, 1],\n",
       " [2, 3932, 1],\n",
       " [2, 1504, 1],\n",
       " [2, 1317, 61],\n",
       " [2, 6014, 61],\n",
       " [2, 7128, 61],\n",
       " [2, 6015, 61],\n",
       " [2, 6015, 1],\n",
       " [2, 60, 8],\n",
       " [2, 3431, 61],\n",
       " [2, 533, 61],\n",
       " [2, 1446, 61],\n",
       " [2, 7129, 61],\n",
       " [2, 175, 61],\n",
       " [2, 7130, 61, 7131, 61],\n",
       " [2, 7131, 61],\n",
       " [2, 6016, 61],\n",
       " [2, 6017, 1],\n",
       " [2, 8788, 61],\n",
       " [2, 32, 61],\n",
       " [2, 2162, 61],\n",
       " [2, 483, 61],\n",
       " [2, 3039, 1],\n",
       " [2, 2163, 1],\n",
       " [2, 3225, 1],\n",
       " [2, 1504, 1],\n",
       " [2, 2164, 794, 61],\n",
       " [2, 8789, 794, 61],\n",
       " [2, 7132, 794, 1],\n",
       " [2, 15, 11933, 1],\n",
       " [2, 15, 5276, 1],\n",
       " [2, 15, 11934, 1],\n",
       " [2, 15, 7133, 1],\n",
       " [2, 2456, 1],\n",
       " [2, 3933, 1],\n",
       " [2, 19, 606, 1],\n",
       " [2, 64, 1582, 61],\n",
       " [2, 2457, 6, 61],\n",
       " [2, 8790, 25, 6018, 1],\n",
       " [2, 533, 61],\n",
       " [2, 7129, 61],\n",
       " [2, 11935, 61],\n",
       " [2, 8791, 61],\n",
       " [2, 8791, 61],\n",
       " [2, 3934, 61],\n",
       " [2, 3226, 1],\n",
       " [2, 36, 2086, 61],\n",
       " [2, 11936, 61],\n",
       " [2, 2086, 61],\n",
       " [2, 11937, 61],\n",
       " [2, 11938, 61],\n",
       " [2, 1222, 1],\n",
       " [2, 302, 78, 155, 1],\n",
       " [2, 3935, 78, 155, 1],\n",
       " [2, 479, 78, 155, 1],\n",
       " [2, 2349, 78, 155, 1],\n",
       " [2, 302, 80, 1],\n",
       " [2, 3935, 80, 1],\n",
       " [2, 479, 80, 1],\n",
       " [2, 2349, 80, 1],\n",
       " [2, 19, 41, 61],\n",
       " [2, 19, 11939, 8],\n",
       " [2, 3648, 8],\n",
       " [2, 5, 1246, 1],\n",
       " [2, 3649, 1247, 1],\n",
       " [2, 8792, 1],\n",
       " [2, 15, 3432, 1],\n",
       " [2, 15, 3433, 1],\n",
       " [2, 7134, 1],\n",
       " [2, 15, 3936, 1],\n",
       " [2, 11940, 1],\n",
       " [2, 15, 11941, 1],\n",
       " [2, 31, 19, 16, 1],\n",
       " [2, 1897, 1],\n",
       " [2, 3040, 1],\n",
       " [2, 577, 1],\n",
       " [2, 8793, 1],\n",
       " [2, 3937, 1],\n",
       " [2, 19, 234, 1],\n",
       " [2, 5277, 1],\n",
       " [2, 4299, 1],\n",
       " [2, 4300, 1],\n",
       " [2, 35, 716, 1],\n",
       " [2, 41, 7135, 1],\n",
       " [2, 35, 1898, 1],\n",
       " [2, 995, 1],\n",
       " [2, 1223, 1],\n",
       " [2, 5278, 1],\n",
       " [2, 6, 70, 86, 61],\n",
       " [2, 10, 484, 522, 1],\n",
       " [2, 10, 484, 522, 61],\n",
       " [2, 1034, 61],\n",
       " [2, 10, 395, 1618, 61],\n",
       " [2, 10, 33, 66, 61],\n",
       " [2, 201, 6019, 61],\n",
       " [2, 8794, 61],\n",
       " [2, 11942, 61],\n",
       " [2, 201, 13, 6020, 61],\n",
       " [2, 13, 784, 8],\n",
       " [2, 11, 100, 8],\n",
       " [2, 260, 61],\n",
       " [2, 260, 1],\n",
       " [2, 8795, 1],\n",
       " [2, 19, 11943, 1],\n",
       " [2, 3650, 1],\n",
       " [2, 18, 4, 31, 8],\n",
       " [2, 1540, 9, 7, 1],\n",
       " [2, 1540, 1],\n",
       " [2, 3431, 61],\n",
       " [2, 1665, 13, 1505, 1],\n",
       " [2, 2837, 1846, 1],\n",
       " [2, 16, 557, 1],\n",
       " [2, 16, 207, 1],\n",
       " [2, 16, 187, 1],\n",
       " [2, 1506, 951, 1],\n",
       " [2, 1506, 870, 1],\n",
       " [2, 264, 187, 1],\n",
       " [2, 264, 207, 1],\n",
       " [2, 2838, 951, 1],\n",
       " [2, 2838, 870, 1],\n",
       " [2, 2838, 11944, 1],\n",
       " [2, 16, 930, 1],\n",
       " [2, 11945, 1],\n",
       " [2, 1291, 1],\n",
       " [2, 8796, 1],\n",
       " [2, 1291, 1],\n",
       " [2, 11946, 1],\n",
       " [2, 541, 1],\n",
       " [2, 635, 1],\n",
       " [2, 6021, 61],\n",
       " [2, 3431, 61],\n",
       " [2, 8797, 1],\n",
       " [2, 3431, 61],\n",
       " [2, 8798, 1],\n",
       " [2, 3938, 9, 7, 1],\n",
       " [2, 8799, 1],\n",
       " [2, 6017, 1],\n",
       " [2, 646, 1],\n",
       " [2, 1897, 1],\n",
       " [2, 4301, 1],\n",
       " [2, 4713, 1],\n",
       " [2, 1052, 10, 42, 61],\n",
       " [2, 4714, 61],\n",
       " [2, 2252, 10, 42, 61],\n",
       " [2, 621, 61],\n",
       " [2, 1052, 80, 61],\n",
       " [2, 3431, 61],\n",
       " [2, 9, 11, 566, 61],\n",
       " [2, 1052, 10, 42, 61],\n",
       " [2, 4714, 61],\n",
       " [2, 621, 61],\n",
       " [2, 1052, 80, 61],\n",
       " [2, 3431, 61],\n",
       " [2, 11947, 1],\n",
       " [2, 3932, 1],\n",
       " [2, 1052, 9, 48, 1],\n",
       " [2, 479, 916, 1],\n",
       " [2, 161, 1199, 61],\n",
       " [2, 161, 11, 693, 1],\n",
       " [2, 11948, 61],\n",
       " [2, 483, 61],\n",
       " [2, 483, 14, 261, 61],\n",
       " [2, 14, 1120, 61],\n",
       " [2, 3938, 4302, 1],\n",
       " [2, 5, 189, 1],\n",
       " [2, 5, 2350, 1],\n",
       " [2, 1541, 1],\n",
       " [2, 1541, 1],\n",
       " [2, 7136, 20, 284, 1],\n",
       " [2, 1541, 1],\n",
       " [2, 6022, 1],\n",
       " [2, 1504, 7, 61],\n",
       " [2, 5279, 9, 7, 1],\n",
       " [2, 483, 1],\n",
       " [2, 8800, 1],\n",
       " [2, 11949, 1],\n",
       " [2, 11950, 1],\n",
       " [2, 11951, 1],\n",
       " [2, 11952, 1],\n",
       " [2, 11953, 1],\n",
       " [2, 11954, 1],\n",
       " [2, 11955, 1],\n",
       " [2, 11956, 1],\n",
       " [2, 8801, 1],\n",
       " [2, 3938, 4302, 1],\n",
       " [2, 8802, 9, 7, 1],\n",
       " [2, 35, 10, 251, 1],\n",
       " [2, 10, 251, 1],\n",
       " [2, 15, 8803, 1],\n",
       " [2, 3934, 1],\n",
       " [2, 15, 11957, 1],\n",
       " [2, 15, 8804, 1],\n",
       " [2, 15, 665, 1847, 1],\n",
       " [2, 15, 64, 11958, 1],\n",
       " [2, 15, 6023, 1],\n",
       " [2, 15, 7137, 1],\n",
       " [2, 15, 64, 8805, 1],\n",
       " [2, 1619, 1],\n",
       " [2, 19, 1174, 1],\n",
       " [2, 705, 1],\n",
       " [2, 79, 7, 1],\n",
       " [2, 35, 1475, 1],\n",
       " [2, 79, 1955, 1],\n",
       " [2, 35, 13, 622, 1],\n",
       " [2, 35, 8806, 1],\n",
       " [2, 79, 410, 1],\n",
       " [2, 79, 1583, 1],\n",
       " [2, 35, 4303, 1],\n",
       " [2, 17, 65, 1],\n",
       " [2, 79, 31, 1],\n",
       " [2, 79, 31, 1],\n",
       " [2, 11959, 9, 145, 1],\n",
       " [2, 16, 342, 281, 1],\n",
       " [2, 7138, 1],\n",
       " [2, 411, 8807, 1],\n",
       " [2, 2351, 5, 5280, 1],\n",
       " [2, 31, 221, 1],\n",
       " [2, 1112, 1],\n",
       " [2, 941, 61],\n",
       " [2, 11960, 1],\n",
       " [2, 11961, 1],\n",
       " [2, 11962, 1],\n",
       " [2, 11963, 1],\n",
       " [2, 11964, 1],\n",
       " [2, 11965, 1],\n",
       " [2, 11966, 1],\n",
       " [2, 11967, 1],\n",
       " [2, 75, 1447, 1],\n",
       " [2, 11968, 1],\n",
       " [2, 8808, 1],\n",
       " [2, 3939, 1],\n",
       " [2, 885, 11, 807, 61],\n",
       " [2, 4304, 5, 3227, 61],\n",
       " [2, 11969, 1],\n",
       " [2, 161, 11, 693, 1],\n",
       " [2, 161, 1199, 1],\n",
       " [2, 7139, 1],\n",
       " [2, 11970, 1],\n",
       " [2, 7140, 1],\n",
       " [2, 4715, 1],\n",
       " [2, 2024, 1],\n",
       " [2, 7, 654, 1],\n",
       " [2, 7, 1246, 1],\n",
       " [2, 7, 942, 1],\n",
       " [2, 5281, 981, 1],\n",
       " [2, 2087, 61],\n",
       " [2, 8809, 61],\n",
       " [2, 11971, 61],\n",
       " [2, 2087, 1],\n",
       " [2, 2691, 30, 468, 1],\n",
       " [2, 75, 7141, 1],\n",
       " [2, 19, 871, 1],\n",
       " [2, 2165, 1],\n",
       " [2, 3940, 1],\n",
       " [2, 6024, 1],\n",
       " [2, 60, 654, 8],\n",
       " [2, 60, 3933, 8],\n",
       " [2, 60, 1246, 8],\n",
       " [2, 60, 942, 8],\n",
       " [2, 60, 54, 1582, 8],\n",
       " [2, 18, 4, 6, 8],\n",
       " [2, 1317, 1],\n",
       " [2, 117, 1582, 1],\n",
       " [2, 35, 1475, 8],\n",
       " [2, 35, 1955, 8],\n",
       " [2, 8810, 1],\n",
       " [2, 8810, 1],\n",
       " [2, 11972, 1],\n",
       " [2, 8811, 61],\n",
       " [2, 8812, 1],\n",
       " [2, 16, 14, 147, 1],\n",
       " [2, 16, 365, 1],\n",
       " [2, 16, 1706, 1],\n",
       " [2, 264, 1706, 1],\n",
       " [2, 2838, 7142, 1],\n",
       " [2, 2837, 1847, 1],\n",
       " [2, 6, 22, 3434, 1],\n",
       " [2, 2839, 9, 73, 61],\n",
       " [2, 2839, 9, 73, 61],\n",
       " [2, 8813, 9, 73, 61],\n",
       " [2, 11973, 1],\n",
       " [2, 636, 1],\n",
       " [2, 4305, 61],\n",
       " [2, 11974, 1],\n",
       " [2, 6, 22, 694, 1],\n",
       " [2, 2163, 1],\n",
       " [2, 11975, 9, 73, 1],\n",
       " [2, 8814, 9, 73, 1],\n",
       " [2, 11976, 9, 73, 1],\n",
       " [2, 11977, 9, 73, 1],\n",
       " [2, 4716, 9, 7, 1],\n",
       " [2, 7143, 9, 7, 1],\n",
       " [2, 6025, 45, 1],\n",
       " [2, 1052, 10, 42, 61],\n",
       " [2, 4714, 61],\n",
       " [2, 621, 61],\n",
       " [2, 1052, 80, 61],\n",
       " [2, 906, 1],\n",
       " [2, 6026, 1],\n",
       " [2, 11978, 61],\n",
       " [2, 1052, 10, 42, 61],\n",
       " [2, 4714, 61],\n",
       " [2, 621, 61],\n",
       " [2, 1052, 80, 61],\n",
       " [2, 11979, 1],\n",
       " [2, 2087, 61],\n",
       " [2, 4306, 65, 61],\n",
       " [2, 1112, 27, 352, 1],\n",
       " [2, 1035, 1],\n",
       " [2, 1035, 1],\n",
       " [2, 541, 1],\n",
       " [2, 1707, 1],\n",
       " [2, 6021, 1],\n",
       " [2, 1707, 1],\n",
       " [2, 11980, 1],\n",
       " [2, 11981, 8],\n",
       " [2, 151, 83, 61],\n",
       " [2, 6027, 9, 7, 1],\n",
       " [2, 11982, 1],\n",
       " [2, 8815, 1],\n",
       " [2, 6028, 65, 1],\n",
       " [2, 6029, 65, 1],\n",
       " [2, 5, 416, 1],\n",
       " [2, 5, 19, 1318, 1],\n",
       " [2, 5, 996, 1],\n",
       " [2, 175, 9, 7, 1],\n",
       " [2, 1504, 4, 62, 8],\n",
       " [2, 8816, 7144, 1],\n",
       " [2, 4, 411, 11983, 8],\n",
       " [2, 951, 1],\n",
       " [2, 4, 380, 257, 106, 8],\n",
       " [2, 1504, 18, 42, 1],\n",
       " [2, 4, 3435, 61],\n",
       " [2, 4, 72, 1795, 8],\n",
       " [2, 37, 10, 1795, 8],\n",
       " [2, 4717, 5, 52, 1],\n",
       " [2, 11984, 1],\n",
       " [2, 2164, 794, 61],\n",
       " [2, 3651, 1],\n",
       " [2, 8789, 794, 1],\n",
       " [2, 11985, 1],\n",
       " [2, 11986, 1],\n",
       " [2, 4307, 1],\n",
       " [2, 8817, 1],\n",
       " [2, 35, 410, 1],\n",
       " [2, 15, 19, 1072, 1],\n",
       " [2, 15, 11, 1072, 1],\n",
       " [2, 46, 69, 1],\n",
       " [2, 11987, 1],\n",
       " [2, 11988, 1],\n",
       " [2, 19, 235, 65, 1],\n",
       " [2, 19, 235, 1],\n",
       " [2, 7145, 1],\n",
       " [2, 19, 738, 1],\n",
       " [2, 15, 30, 3041, 1],\n",
       " [2, 19, 558, 1],\n",
       " [2, 19, 41, 1],\n",
       " [2, 6017, 1],\n",
       " [2, 849, 18, 285, 1],\n",
       " [2, 15, 3652, 1],\n",
       " [2, 8793, 1],\n",
       " [2, 2350, 1],\n",
       " [2, 15, 2166, 1],\n",
       " [2, 19, 197, 1],\n",
       " [2, 11989, 1],\n",
       " [2, 7146, 1],\n",
       " [2, 15, 665, 1],\n",
       " [2, 872, 1],\n",
       " [2, 1956, 1],\n",
       " [2, 8818, 1],\n",
       " [2, 11990, 1],\n",
       " [2, 31, 19, 1542, 1],\n",
       " [2, 982, 1],\n",
       " [2, 31, 2167, 1],\n",
       " [2, 64, 1036, 1],\n",
       " [2, 35, 10, 507, 1],\n",
       " [2, 79, 1957, 1],\n",
       " [2, 35, 1957, 1],\n",
       " [2, 35, 4308, 1],\n",
       " [2, 35, 1846, 1],\n",
       " [2, 64, 567, 1],\n",
       " [2, 35, 1270, 1],\n",
       " [2, 19, 234, 1],\n",
       " [2, 79, 268, 11991, 1],\n",
       " [2, 79, 557, 1],\n",
       " [2, 35, 1755, 1],\n",
       " [2, 79, 461, 61],\n",
       " [2, 31, 79, 461, 1],\n",
       " [2, 35, 647, 1],\n",
       " [2, 35, 907, 1],\n",
       " [2, 80, 15, 4309, 1],\n",
       " [2, 35, 42, 1],\n",
       " [2, 35, 13, 48, 1],\n",
       " [2, 35, 886, 1],\n",
       " [2, 305, 122, 1],\n",
       " [2, 79, 2352, 1],\n",
       " [2, 35, 1584, 1],\n",
       " [2, 79, 547, 1],\n",
       " [2, 15, 850, 9, 21, 1],\n",
       " [2, 35, 1755, 1],\n",
       " [2, 79, 997, 1],\n",
       " [2, 79, 1319, 1],\n",
       " [2, 79, 512, 1],\n",
       " [2, 35, 9, 952, 1],\n",
       " [2, 35, 1148, 1],\n",
       " [2, 79, 3042, 1],\n",
       " [2, 35, 1410, 1],\n",
       " [2, 79, 3941, 1],\n",
       " [2, 35, 7147, 1],\n",
       " [2, 35, 1708, 1],\n",
       " [2, 79, 396, 1],\n",
       " [2, 1796, 1],\n",
       " [2, 33, 175, 1],\n",
       " [2, 655, 1],\n",
       " [2, 717, 1],\n",
       " [2, 12, 7, 1],\n",
       " [2, 12, 572, 1],\n",
       " [2, 12, 1224, 1],\n",
       " [2, 12, 138, 1],\n",
       " [2, 12, 513, 1],\n",
       " [2, 12, 410, 1],\n",
       " [2, 12, 739, 1],\n",
       " [2, 12, 674, 1],\n",
       " [2, 1585, 480, 1],\n",
       " [2, 6, 528, 1],\n",
       " [2, 6030, 9, 73, 1],\n",
       " [2, 6030, 9, 73, 1],\n",
       " [2, 11992, 9, 73, 1],\n",
       " [2, 1899, 1],\n",
       " [2, 391, 1],\n",
       " [2, 3436, 1],\n",
       " [2, 3043, 1],\n",
       " [2, 228, 1],\n",
       " [2, 3431, 61],\n",
       " [2, 3431, 61],\n",
       " [2, 496, 1],\n",
       " [2, 11993, 186, 1],\n",
       " [2, 46, 69, 8],\n",
       " [2, 11994, 9, 7, 1],\n",
       " [2, 23, 189, 1],\n",
       " [2, 23, 266, 1],\n",
       " [2, 23, 1317, 1],\n",
       " [2, 3044, 61],\n",
       " [2, 1958, 1],\n",
       " [2, 3044, 1],\n",
       " [2, 1958, 42, 1],\n",
       " [2, 872, 34, 365, 61],\n",
       " [2, 218, 34, 365, 1],\n",
       " [2, 218, 34, 314, 61],\n",
       " [2, 3653, 1],\n",
       " [2, 14, 261, 1],\n",
       " [2, 3942, 61],\n",
       " [2, 10, 587, 61],\n",
       " [2, 6, 22, 3434, 1],\n",
       " [2, 3943, 9, 7, 1],\n",
       " [2, 4310, 9, 7, 1],\n",
       " [2, 6031, 9, 7, 1],\n",
       " [2, 1448, 61],\n",
       " [2, 3431, 61],\n",
       " [2, 71, 3654, 1],\n",
       " [2, 7, 189, 1],\n",
       " [2, 7, 54, 612, 1],\n",
       " [2, 7, 16, 568, 1],\n",
       " [2, 7, 19, 150, 1],\n",
       " [2, 7, 132, 11995, 10, 599, 1],\n",
       " [2, 7, 16, 49, 1],\n",
       " [2, 7, 1666, 1],\n",
       " [2, 73, 2692, 1],\n",
       " [2, 7, 453, 1],\n",
       " [2, 7, 1091, 1],\n",
       " [2, 7, 2350, 1],\n",
       " [2, 7, 3045, 1],\n",
       " [2, 7, 1271, 1],\n",
       " [2, 7, 16, 54, 1898, 1],\n",
       " [2, 119, 122, 1],\n",
       " [2, 1756, 13, 21, 1],\n",
       " [2, 3228, 10, 1848, 1],\n",
       " [2, 996, 14, 104, 1],\n",
       " [2, 7148, 14, 104, 1],\n",
       " [2, 6032, 14, 104, 1],\n",
       " [2, 6032, 45, 1],\n",
       " [2, 6033, 45, 1],\n",
       " [2, 996, 45, 1],\n",
       " [2, 998, 45, 1],\n",
       " [2, 7149, 9, 7, 1],\n",
       " [2, 11996, 9, 7, 1],\n",
       " [2, 11997, 9, 7, 1],\n",
       " [2, 7149, 9, 7, 1],\n",
       " [2, 3655, 1],\n",
       " [2, 11998, 1],\n",
       " [2, 11999, 1],\n",
       " [2, 12000, 1],\n",
       " [2, 8819, 1],\n",
       " [2, 135, 10, 251, 1],\n",
       " [2, 19, 5282, 1],\n",
       " [2, 1620, 1],\n",
       " [2, 135, 65, 1],\n",
       " [2, 32, 4, 8],\n",
       " [2, 4, 572, 61],\n",
       " [2, 60, 79, 31, 8],\n",
       " [2, 60, 189, 8],\n",
       " [2, 60, 266, 8],\n",
       " [2, 60, 16, 8820, 8],\n",
       " [2, 60, 16, 568, 8],\n",
       " [2, 60, 453, 8],\n",
       " [2, 60, 1091, 8],\n",
       " [2, 60, 16, 54, 417, 8],\n",
       " [2, 60, 19, 54, 917, 8],\n",
       " [2, 60, 3045, 8],\n",
       " [2, 60, 12, 5, 8],\n",
       " [2, 3437, 1],\n",
       " [2, 2840, 1],\n",
       " [2, 117, 422, 1],\n",
       " [2, 12001, 1],\n",
       " [2, 968, 422, 1],\n",
       " [2, 453, 105, 1],\n",
       " [2, 54, 422, 105, 1],\n",
       " [2, 2458, 205, 1],\n",
       " [2, 288, 422, 205, 1],\n",
       " [2, 249, 10, 136, 1],\n",
       " [2, 29, 559, 1],\n",
       " [2, 105, 559, 1],\n",
       " [2, 249, 10, 105, 1],\n",
       " [2, 249, 10, 1014, 1],\n",
       " [2, 3944, 1, 533, 61],\n",
       " [2, 6034, 1],\n",
       " [2, 12002, 1],\n",
       " [2, 12003, 1],\n",
       " [2, 16, 3945, 1],\n",
       " [2, 27, 1149, 3946, 1],\n",
       " [2, 4718, 1],\n",
       " [2, 509, 9, 48, 61],\n",
       " [2, 4305, 1],\n",
       " [2, 8821, 1],\n",
       " [2, 1507, 13, 1073, 1],\n",
       " [2, 8790, 25, 6018, 1],\n",
       " [2, 1292, 14, 683, 1],\n",
       " [2, 224, 69, 8],\n",
       " [2, 224, 1621, 8],\n",
       " [2, 224, 8822, 8],\n",
       " [2, 12004, 9, 73, 61],\n",
       " [2, 12005, 1],\n",
       " [2, 12006, 1],\n",
       " [2, 12007, 1],\n",
       " [2, 12008, 1],\n",
       " [2, 808, 1],\n",
       " [2, 3656, 1],\n",
       " [2, 418, 1],\n",
       " [2, 1959, 42, 1],\n",
       " [2, 418, 9, 48, 1],\n",
       " [2, 1959, 42, 1],\n",
       " [2, 4719, 1],\n",
       " [2, 7150, 1],\n",
       " [2, 636, 42, 1],\n",
       " [2, 808, 204, 1],\n",
       " [2, 31, 1796, 8],\n",
       " [2, 1796, 8],\n",
       " [2, 1136, 78, 1],\n",
       " [2, 27, 523, 12009, 1],\n",
       " [2, 6, 3657, 1],\n",
       " [2, 6, 2088, 1],\n",
       " [2, 6, 2088, 61],\n",
       " [2, 6, 2088, 61],\n",
       " [2, 6, 12010, 1],\n",
       " [2, 6, 12011, 1],\n",
       " [2, 6, 4299, 1],\n",
       " [2, 6, 2088, 1],\n",
       " [2, 6, 22, 3438, 61],\n",
       " [2, 6, 12012, 1],\n",
       " [2, 6, 6035, 1],\n",
       " [2, 3229, 61],\n",
       " [2, 12, 1797, 61],\n",
       " [2, 3431, 61],\n",
       " [2, 12013, 45, 1],\n",
       " [2, 12014, 45, 1],\n",
       " [2, 12015, 45, 1],\n",
       " [2, 12016, 45, 1],\n",
       " [2, 12017, 45, 1],\n",
       " [2, 6036, 1],\n",
       " [2, 12018, 1],\n",
       " [2, 8823, 1],\n",
       " [2, 1899, 1],\n",
       " [2, 12019, 1],\n",
       " [2, 4720, 10, 21, 1],\n",
       " [2, 12020, 1],\n",
       " [2, 12021, 10, 21, 1],\n",
       " [2, 7151, 1],\n",
       " [2, 1507, 9, 599, 1],\n",
       " [2, 302, 9, 18, 599, 1],\n",
       " [2, 302, 9, 4721, 1],\n",
       " [2, 302, 9, 18, 599, 1],\n",
       " [2, 1052, 9, 18, 599, 1],\n",
       " [2, 3935, 9, 18, 599, 1],\n",
       " [2, 1707, 1],\n",
       " [2, 1052, 9, 11, 240, 1],\n",
       " [2, 7140, 1],\n",
       " [2, 3938, 45, 1],\n",
       " [2, 1622, 1709, 1],\n",
       " [2, 732, 55, 1],\n",
       " [2, 824, 1709, 1],\n",
       " [2, 5, 12, 410, 1],\n",
       " [2, 5, 12, 1092, 1],\n",
       " [2, 5, 16, 4311, 1],\n",
       " [2, 1053, 1],\n",
       " [2, 5, 12, 7152, 1],\n",
       " [2, 5, 12, 3230, 1],\n",
       " [2, 5, 12, 207, 1],\n",
       " [2, 5, 12, 512, 1],\n",
       " [2, 12, 512, 1],\n",
       " [2, 429, 35, 1],\n",
       " [2, 3947, 45, 1],\n",
       " [2, 4, 7153, 61],\n",
       " [2, 4, 1074, 61],\n",
       " [2, 37, 17, 7, 8],\n",
       " [2, 7154, 9, 7, 1],\n",
       " [2, 35, 647, 1],\n",
       " [2, 35, 907, 1],\n",
       " [2, 79, 207, 1],\n",
       " [2, 35, 1148, 1],\n",
       " [2, 35, 1900, 1],\n",
       " [2, 22, 19, 4722, 1],\n",
       " [2, 22, 19, 4723, 1],\n",
       " [2, 12022, 1],\n",
       " [2, 46, 1543, 1],\n",
       " [2, 46, 753, 1],\n",
       " [2, 16, 753, 1],\n",
       " [2, 16, 1544, 1],\n",
       " [2, 887, 1960, 1],\n",
       " [2, 12023, 1],\n",
       " [2, 577, 11, 5283, 1],\n",
       " [2, 665, 2693, 1],\n",
       " [2, 19, 588, 1],\n",
       " [2, 15, 8824, 1],\n",
       " [2, 5284, 11, 1757, 1],\n",
       " [2, 5285, 1],\n",
       " [2, 22, 558, 1],\n",
       " [2, 22, 3231, 1],\n",
       " [2, 80, 22, 3231, 1],\n",
       " [2, 19, 234, 1],\n",
       " [2, 15, 1710, 1],\n",
       " [2, 15, 7155, 1],\n",
       " [2, 7146, 1],\n",
       " [2, 19, 445, 1],\n",
       " [2, 15, 11, 2567, 1],\n",
       " [2, 15, 11, 1292, 1],\n",
       " [2, 6037, 9, 7, 1],\n",
       " [2, 1137, 9, 7, 1],\n",
       " [2, 33, 206, 1],\n",
       " [2, 15, 8825, 1],\n",
       " [2, 15, 12024, 1],\n",
       " [2, 19, 150, 1],\n",
       " [2, 15, 4724, 1],\n",
       " [2, 15, 51, 1],\n",
       " [2, 19, 1961, 61],\n",
       " [2, 15, 398, 1],\n",
       " [2, 416, 13, 784, 1],\n",
       " [2, 19, 1150, 13, 784, 1],\n",
       " [2, 416, 13, 784, 1],\n",
       " [2, 19, 830, 13, 569, 1],\n",
       " [2, 19, 830, 10, 241, 1],\n",
       " [2, 19, 8826, 1],\n",
       " [2, 19, 121, 1],\n",
       " [2, 197, 9, 7, 1],\n",
       " [2, 24, 197, 1],\n",
       " [2, 19, 197, 1],\n",
       " [2, 197, 202, 1],\n",
       " [2, 197, 9, 202, 1],\n",
       " [2, 1200, 9, 202, 1],\n",
       " [2, 22, 197, 1],\n",
       " [2, 22, 64, 195, 1],\n",
       " [2, 350, 9, 7, 1],\n",
       " [2, 15, 8827, 1],\n",
       " [2, 640, 674, 1],\n",
       " [2, 31, 8828, 1],\n",
       " [2, 31, 12025, 1],\n",
       " [2, 7156, 1],\n",
       " [2, 12026, 1],\n",
       " [2, 12027, 1],\n",
       " [2, 19, 1449, 1],\n",
       " [2, 2089, 1],\n",
       " [2, 12028, 1],\n",
       " [2, 12029, 1],\n",
       " [2, 12030, 1],\n",
       " [2, 91, 9, 262, 1],\n",
       " [2, 79, 14, 147, 1],\n",
       " [2, 79, 14, 12031, 1],\n",
       " [2, 35, 63, 1],\n",
       " [2, 35, 366, 1],\n",
       " [2, 31, 35, 63, 1],\n",
       " [2, 31, 35, 366, 1],\n",
       " [2, 35, 943, 1],\n",
       " [2, 35, 2168, 1],\n",
       " [2, 35, 981, 1],\n",
       " [2, 79, 2841, 1],\n",
       " [2, 35, 178, 96, 1],\n",
       " [2, 35, 4725, 1],\n",
       " [2, 35, 178, 1623, 1],\n",
       " [2, 6, 41, 1623, 1],\n",
       " [2, 35, 542, 1],\n",
       " [2, 35, 944, 1],\n",
       " [2, 35, 8829, 1],\n",
       " [2, 35, 8830, 1],\n",
       " [2, 15, 35, 2353, 1],\n",
       " [2, 79, 5, 559, 1],\n",
       " [2, 91, 5, 559, 1],\n",
       " [2, 15, 850, 559, 1],\n",
       " [2, 31, 91, 559, 1],\n",
       " [2, 79, 154, 1],\n",
       " [2, 35, 154, 1],\n",
       " [2, 79, 5286, 1],\n",
       " [2, 79, 8831, 1],\n",
       " [2, 79, 8832, 1],\n",
       " [2, 35, 396, 61],\n",
       " [2, 35, 396, 1],\n",
       " [2, 19, 222, 1],\n",
       " [2, 31, 35, 325, 1],\n",
       " [2, 31, 35, 1054, 1],\n",
       " [2, 79, 795, 1],\n",
       " [2, 79, 1075, 1],\n",
       " [2, 79, 1224, 1],\n",
       " [2, 64, 422, 1],\n",
       " [2, 7157, 1],\n",
       " [2, 6, 530, 440, 1],\n",
       " [2, 17, 65, 7, 8],\n",
       " [2, 17, 7, 8],\n",
       " [2, 12, 2090, 8],\n",
       " [2, 12, 547, 8],\n",
       " [2, 17, 471, 8],\n",
       " [2, 101, 29, 8],\n",
       " [2, 16, 2842, 1],\n",
       " [2, 6, 19, 1320, 1],\n",
       " [2, 2568, 1],\n",
       " [2, 1586, 1],\n",
       " [2, 12032, 1],\n",
       " [2, 1508, 1],\n",
       " [2, 3046, 1],\n",
       " [2, 3948, 1],\n",
       " [2, 2459, 1],\n",
       " [2, 56, 30, 1],\n",
       " [2, 12, 14, 1509, 1],\n",
       " [2, 108, 329, 1],\n",
       " [2, 17, 329, 1],\n",
       " [2, 17, 329, 1],\n",
       " [2, 17, 1476, 1],\n",
       " [2, 17, 1321, 1],\n",
       " [2, 17, 396, 61],\n",
       " [2, 17, 941, 1],\n",
       " [2, 17, 65, 1],\n",
       " [2, 12, 207, 1],\n",
       " [2, 17, 42, 1],\n",
       " [2, 12, 10, 23, 1],\n",
       " [2, 12, 122, 1],\n",
       " [2, 12, 441, 1],\n",
       " [2, 12, 607, 1],\n",
       " [2, 12, 930, 1],\n",
       " [2, 108, 151, 77, 1],\n",
       " [2, 613, 1],\n",
       " [2, 17, 65, 1],\n",
       " [2, 12, 237, 1],\n",
       " [2, 12, 11, 281, 1],\n",
       " [2, 16, 718, 1],\n",
       " [2, 16, 402, 1],\n",
       " [2, 54, 999, 5, 261, 1],\n",
       " [2, 12, 11, 133, 1],\n",
       " [2, 12, 5, 261, 1],\n",
       " [2, 54, 999, 11, 133, 1],\n",
       " [2, 12, 100, 61],\n",
       " [2, 12, 100, 1],\n",
       " [2, 12, 21, 83, 1],\n",
       " [2, 12033, 1],\n",
       " [2, 12034, 1],\n",
       " [2, 12035, 1],\n",
       " [2, 2694, 45, 1],\n",
       " [2, 4726, 45, 1],\n",
       " [2, 2694, 45, 1],\n",
       " [2, 12036, 45, 1],\n",
       " [2, 5287, 45, 1],\n",
       " [2, 1665, 825, 1],\n",
       " [2, 4312, 825, 1],\n",
       " [2, 7158, 825, 1],\n",
       " [2, 7158, 7159, 1],\n",
       " [2, 1665, 7159, 1],\n",
       " [2, 4312, 7159, 1],\n",
       " [2, 7160, 6038, 1],\n",
       " [2, 7160, 12037, 1],\n",
       " [2, 1899, 9, 73, 1],\n",
       " [2, 1899, 9, 73, 1],\n",
       " [2, 5288, 9, 73, 1],\n",
       " [2, 78, 8833, 1],\n",
       " [2, 78, 1052, 1],\n",
       " [2, 78, 4714, 1],\n",
       " [2, 391, 6039, 61],\n",
       " [2, 5289, 61],\n",
       " [2, 3047, 69, 61],\n",
       " [2, 3047, 69, 61],\n",
       " [2, 391, 528, 1],\n",
       " [2, 3047, 528, 1],\n",
       " [2, 3436, 528, 1],\n",
       " [2, 2695, 1],\n",
       " [2, 1711, 1],\n",
       " [2, 7161, 61],\n",
       " [2, 6026, 13, 1037, 1],\n",
       " [2, 1665, 1847, 13, 5, 719, 1],\n",
       " [2, 995, 1],\n",
       " [2, 462, 32, 239, 381, 1],\n",
       " [2, 462, 32, 239, 381, 1],\n",
       " [2, 1293, 32, 239, 381, 1],\n",
       " [2, 3658, 32, 239, 381, 1],\n",
       " [2, 462, 293, 873, 61],\n",
       " [2, 462, 873, 1],\n",
       " [2, 1293, 873, 1],\n",
       " [2, 3659, 873, 1],\n",
       " [2, 462, 42, 1],\n",
       " [2, 3659, 42, 1],\n",
       " [2, 3658, 42, 1],\n",
       " [2, 12038, 1],\n",
       " [2, 8798, 1],\n",
       " [2, 12039, 1],\n",
       " [2, 12040, 1],\n",
       " [2, 4727, 9, 14, 381, 1],\n",
       " [2, 319, 740, 1],\n",
       " [2, 3439, 5, 8834, 1],\n",
       " [2, 319, 480, 1],\n",
       " [2, 151, 1510, 61],\n",
       " [2, 18, 2169, 61],\n",
       " [2, 7129, 61],\n",
       " [2, 533, 9, 12041, 61],\n",
       " [2, 3440, 8],\n",
       " [2, 18, 52, 302, 1],\n",
       " [2, 18, 52, 1052, 1],\n",
       " [2, 18, 52, 8833, 1],\n",
       " [2, 18, 52, 3932, 1],\n",
       " [2, 12042, 1],\n",
       " [2, 12043, 1],\n",
       " [2, 12044, 1],\n",
       " [2, 12045, 1],\n",
       " [2, 1121, 45, 1],\n",
       " [2, 2354, 45, 1],\n",
       " [2, 7162, 45, 1],\n",
       " [2, 8835, 45, 1],\n",
       " [2, 4728, 1504, 1],\n",
       " [2, 9, 21, 4, 15, 12046, 1],\n",
       " [2, 8836, 1272, 1],\n",
       " [2, 8836, 34, 1272, 1],\n",
       " [2, 9, 18, 5, 61],\n",
       " [2, 12047, 61],\n",
       " [2, 12048, 61],\n",
       " [2, 12049, 61],\n",
       " [2, 12050, 61],\n",
       " [2, 13, 784, 8],\n",
       " [2, 23, 19, 606, 1],\n",
       " [2, 23, 19, 4313, 1],\n",
       " [2, 23, 969, 1],\n",
       " [2, 23, 2170, 1],\n",
       " [2, 969, 1],\n",
       " [2, 23, 12, 12051, 1],\n",
       " [2, 17, 37, 14, 245, 1],\n",
       " [2, 17, 10, 732, 706, 44, 12052, 1],\n",
       " [2, 17, 187, 1],\n",
       " [2, 17, 4, 12053, 1],\n",
       " [2, 2355, 42, 1],\n",
       " [2, 2696, 45, 1],\n",
       " [2, 2355, 45, 1],\n",
       " [2, 8837, 45, 1],\n",
       " [2, 2696, 45, 1],\n",
       " [2, 8838, 45, 1],\n",
       " [2, 1958, 44, 6, 22, 3434, 1],\n",
       " [2, 1958, 44, 1076, 1847, 1],\n",
       " [2, 3044, 170, 1],\n",
       " [2, 29, 1665, 1],\n",
       " [2, 1847, 1],\n",
       " [2, 34, 916, 1],\n",
       " [2, 198, 1],\n",
       " [2, 4314, 1],\n",
       " [2, 2171, 11, 1505, 1],\n",
       " [2, 6040, 11, 1505, 1],\n",
       " [2, 1076, 429, 1],\n",
       " [2, 1076, 13, 48, 1],\n",
       " [2, 1665, 3042, 1],\n",
       " [2, 432, 14, 196, 873, 1],\n",
       " [2, 32, 42, 1],\n",
       " [2, 3942, 42, 1],\n",
       " [2, 3949, 42, 1],\n",
       " [2, 12054, 42, 1],\n",
       " [2, 12055, 42, 1],\n",
       " [2, 12056, 42, 1],\n",
       " [2, 8788, 42, 1],\n",
       " [2, 32, 33, 1],\n",
       " [2, 12057, 1],\n",
       " [2, 12058, 1],\n",
       " [2, 4315, 61],\n",
       " [2, 22, 12059, 61],\n",
       " [2, 4315, 1],\n",
       " [2, 8839, 1],\n",
       " [2, 1622, 5, 441, 1],\n",
       " [2, 732, 5, 441, 1],\n",
       " [2, 12060, 5, 1201, 1],\n",
       " [2, 732, 5, 1624, 1],\n",
       " [2, 7163, 29, 1],\n",
       " [2, 732, 45, 1],\n",
       " [2, 824, 45, 1],\n",
       " [2, 5290, 45, 1],\n",
       " [2, 732, 45, 1],\n",
       " [2, 260, 61],\n",
       " [2, 260, 9, 136, 1],\n",
       " [2, 260, 1],\n",
       " [2, 33, 12, 1],\n",
       " [2, 79, 31, 1],\n",
       " [2, 89, 79, 31, 1],\n",
       " [2, 589, 4, 8],\n",
       " [2, 3660, 1],\n",
       " [2, 16, 454, 1],\n",
       " [2, 16, 7164, 1],\n",
       " [2, 16, 3232, 1],\n",
       " [2, 2458, 1],\n",
       " [2, 7, 16, 2356, 1],\n",
       " [2, 7, 16, 3432, 1],\n",
       " [2, 7, 16, 7165, 1],\n",
       " [2, 9, 7, 24, 4729, 1],\n",
       " [2, 7, 16, 1798, 1],\n",
       " [2, 9, 7, 24, 392, 1],\n",
       " [2, 7, 1271, 1],\n",
       " [2, 7, 12061, 1],\n",
       " [2, 73, 2460, 1],\n",
       " [2, 7, 17, 65, 1],\n",
       " [2, 7, 17, 626, 1],\n",
       " [2, 7, 17, 1898, 1],\n",
       " [2, 7, 12062, 1],\n",
       " [2, 7, 110, 1],\n",
       " [2, 7, 16, 2357, 1],\n",
       " [2, 7, 16, 3441, 1],\n",
       " [2, 7, 16, 12063, 1],\n",
       " [2, 7, 16, 433, 1],\n",
       " [2, 7, 66, 1],\n",
       " [2, 7, 3442, 1],\n",
       " [2, 73, 19, 606, 1],\n",
       " [2, 73, 19, 1318, 1],\n",
       " [2, 73, 3048, 1],\n",
       " [2, 7, 2170, 1],\n",
       " [2, 7, 2843, 1],\n",
       " [2, 73, 534, 1],\n",
       " [2, 7, 1450, 1],\n",
       " [2, 7, 17, 1475, 1],\n",
       " [2, 7, 17, 542, 1],\n",
       " [2, 7, 17, 674, 1],\n",
       " [2, 7, 12, 1583, 1],\n",
       " [2, 1756, 13, 7, 1],\n",
       " [2, 3228, 10, 138, 1],\n",
       " [2, 12064, 173, 87, 1],\n",
       " [2, 1318, 173, 87, 1],\n",
       " [2, 8840, 1],\n",
       " [2, 1112, 5, 5280, 1],\n",
       " [2, 483, 42, 1],\n",
       " [2, 4730, 42, 1],\n",
       " [2, 3039, 42, 1],\n",
       " [2, 3233, 42, 1],\n",
       " [2, 3950, 9, 7, 1],\n",
       " [2, 8841, 61],\n",
       " [2, 224, 69, 1],\n",
       " [2, 224, 1621, 1],\n",
       " [2, 75, 224, 6039, 1],\n",
       " [2, 19, 7166, 1],\n",
       " [2, 12065, 1],\n",
       " [2, 332, 4316, 1],\n",
       " [2, 75, 5291, 1],\n",
       " [2, 19, 970, 1],\n",
       " [2, 19, 5292, 1],\n",
       " [2, 5293, 1],\n",
       " [2, 145, 1799, 1],\n",
       " [2, 3443, 1],\n",
       " [2, 249, 3443, 1],\n",
       " [2, 80, 3443, 1],\n",
       " [2, 19, 8842, 1],\n",
       " [2, 332, 1582, 61],\n",
       " [2, 65, 149, 1],\n",
       " [2, 4, 62, 8],\n",
       " [2, 9, 60, 24, 392, 8],\n",
       " [2, 60, 2460, 8],\n",
       " [2, 60, 5294, 8],\n",
       " [2, 60, 12, 5, 8],\n",
       " [2, 60, 12, 8],\n",
       " [2, 12066, 1, 1, 1],\n",
       " [2, 60, 16, 433, 8],\n",
       " [2, 60, 1450, 8],\n",
       " [2, 60, 12, 7, 8],\n",
       " [2, 1015, 9, 7, 1],\n",
       " [2, 29, 2569, 1],\n",
       " [2, 3444, 10, 1000, 61],\n",
       " [2, 29, 931, 1],\n",
       " [2, 19, 7167, 1],\n",
       " [2, 29, 58, 1755, 1],\n",
       " [2, 58, 1755, 1],\n",
       " [2, 34, 314, 1],\n",
       " [2, 12067, 34, 314, 1],\n",
       " [2, 59, 9, 3445, 61],\n",
       " [2, 41, 303, 8],\n",
       " [2, 15, 4731, 8],\n",
       " [2, 35, 1667, 8],\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 10459\n",
      "스페인어 단어 집합의 크기 : 20329\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_spa.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}\".format(src_vocab_size))\n",
    "print(\"스페인어 단어 집합의 크기 : {:d}\".format(tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_spa.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_spa.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12432 60449 91592 ... 92099 18998 89774]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0], dtype=int)\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#훈련 데이터와 테스트 데이터 분리\n",
    "n_of_val = int(100000*0.1)\n",
    "print(n_of_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 13)\n",
      "(90000, 17)\n",
      "(90000, 17)\n",
      "(10000, 13)\n",
      "(10000, 17)\n",
      "(10000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원핫 인코딩을 하지 않은 상태로 정수 레이블에 다중 클래스 분류 = sparse_categorical_crossentropy 사용\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     522950      input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     1016450     input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 50)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 50)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50), (None,  20200       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 20329)  1036779     lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,616,579\n",
      "Trainable params: 2,616,579\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 1.6207 - acc: 0.7564 - val_loss: 1.5852 - val_acc: 0.7621\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 95s 68ms/step - loss: 1.5116 - acc: 0.7702 - val_loss: 1.4959 - val_acc: 0.7746\n",
      "Epoch 3/50\n",
      "1407/1407 [==============================] - 96s 68ms/step - loss: 1.4319 - acc: 0.7818 - val_loss: 1.4362 - val_acc: 0.7830\n",
      "Epoch 4/50\n",
      "1407/1407 [==============================] - 93s 66ms/step - loss: 1.3743 - acc: 0.7912 - val_loss: 1.3900 - val_acc: 0.7902\n",
      "Epoch 5/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.3259 - acc: 0.7993 - val_loss: 1.3596 - val_acc: 0.7964\n",
      "Epoch 6/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.2937 - acc: 0.8060 - val_loss: 1.3397 - val_acc: 0.8028\n",
      "Epoch 7/50\n",
      "1407/1407 [==============================] - 94s 67ms/step - loss: 1.2820 - acc: 0.8122 - val_loss: 1.3408 - val_acc: 0.8071\n",
      "Epoch 8/50\n",
      "1407/1407 [==============================] - 94s 67ms/step - loss: 1.2739 - acc: 0.8172 - val_loss: 1.3344 - val_acc: 0.8104\n",
      "Epoch 9/50\n",
      "1407/1407 [==============================] - 94s 67ms/step - loss: 1.2628 - acc: 0.8218 - val_loss: 1.3229 - val_acc: 0.8136\n",
      "Epoch 10/50\n",
      "1407/1407 [==============================] - 95s 68ms/step - loss: 1.2458 - acc: 0.8255 - val_loss: 1.3049 - val_acc: 0.8165\n",
      "Epoch 11/50\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 1.2157 - acc: 0.8289 - val_loss: 1.2768 - val_acc: 0.8200\n",
      "Epoch 12/50\n",
      "1407/1407 [==============================] - 94s 67ms/step - loss: 1.1925 - acc: 0.8322 - val_loss: 1.2702 - val_acc: 0.8211\n",
      "Epoch 13/50\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 1.1853 - acc: 0.8349 - val_loss: 1.2671 - val_acc: 0.8224\n",
      "Epoch 14/50\n",
      "1407/1407 [==============================] - 94s 67ms/step - loss: 1.1789 - acc: 0.8372 - val_loss: 1.2651 - val_acc: 0.8231\n",
      "Epoch 15/50\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 1.1707 - acc: 0.8394 - val_loss: 1.2588 - val_acc: 0.8253\n",
      "Epoch 16/50\n",
      "1407/1407 [==============================] - 95s 68ms/step - loss: 1.1618 - acc: 0.8413 - val_loss: 1.2527 - val_acc: 0.8272\n",
      "Epoch 17/50\n",
      "1407/1407 [==============================] - 94s 67ms/step - loss: 1.1528 - acc: 0.8430 - val_loss: 1.2469 - val_acc: 0.8281\n",
      "Epoch 18/50\n",
      "1407/1407 [==============================] - 99s 70ms/step - loss: 1.1431 - acc: 0.8448 - val_loss: 1.2405 - val_acc: 0.8297\n",
      "Epoch 19/50\n",
      "1407/1407 [==============================] - 98s 70ms/step - loss: 1.1336 - acc: 0.8465 - val_loss: 1.2369 - val_acc: 0.8290\n",
      "Epoch 20/50\n",
      "1407/1407 [==============================] - 100s 71ms/step - loss: 1.1243 - acc: 0.8480 - val_loss: 1.2293 - val_acc: 0.8300\n",
      "Epoch 21/50\n",
      "1407/1407 [==============================] - 94s 66ms/step - loss: 1.1149 - acc: 0.8495 - val_loss: 1.2228 - val_acc: 0.8317\n",
      "Epoch 22/50\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 1.1062 - acc: 0.8508 - val_loss: 1.2191 - val_acc: 0.8320\n",
      "Epoch 23/50\n",
      "1407/1407 [==============================] - 85s 60ms/step - loss: 1.0975 - acc: 0.8520 - val_loss: 1.2148 - val_acc: 0.8327\n",
      "Epoch 24/50\n",
      "1407/1407 [==============================] - 92s 66ms/step - loss: 1.0894 - acc: 0.8531 - val_loss: 1.2078 - val_acc: 0.8335\n",
      "Epoch 25/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0819 - acc: 0.8542 - val_loss: 1.2075 - val_acc: 0.8327\n",
      "Epoch 26/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0751 - acc: 0.8552 - val_loss: 1.2016 - val_acc: 0.8341\n",
      "Epoch 27/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0684 - acc: 0.8559 - val_loss: 1.1989 - val_acc: 0.8340\n",
      "Epoch 28/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0622 - acc: 0.8567 - val_loss: 1.1966 - val_acc: 0.8342\n",
      "Epoch 29/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0568 - acc: 0.8577 - val_loss: 1.1960 - val_acc: 0.8346\n",
      "Epoch 30/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0512 - acc: 0.8583 - val_loss: 1.1923 - val_acc: 0.8355\n",
      "Epoch 31/50\n",
      "1407/1407 [==============================] - 92s 66ms/step - loss: 1.0465 - acc: 0.8589 - val_loss: 1.1948 - val_acc: 0.8338\n",
      "Epoch 32/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0420 - acc: 0.8596 - val_loss: 1.1927 - val_acc: 0.8352\n",
      "Epoch 33/50\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.0378 - acc: 0.8602 - val_loss: 1.1910 - val_acc: 0.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d4a925908>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 64, epochs = 50, callbacks=[callback]) #early stopping 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_src[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  the room is dark . \n",
      "번역문 : la habitacion es oscura . \n",
      "예측문 :  la habitacion esta con la habitacion . \n",
      "\n",
      "\n",
      "원문 :  i go into the city every day . \n",
      "번역문 : yo voy a la ciudad todos los dias . \n",
      "예측문 :  me voy a la ciudad al dia . \n",
      "\n",
      "\n",
      "원문 :  there is no telling what will happen . \n",
      "번역문 : no se sabe que va a pasar . \n",
      "예측문 :  no hay todo lo que quiere . \n",
      "\n",
      "\n",
      "원문 :  he went to the shop . \n",
      "번역문 : ha ido a la tienda . \n",
      "예측문 :  fue a la tienda . \n",
      "\n",
      "\n",
      "원문 :  tom and i chatted for a while . \n",
      "번역문 : tom y yo charlamos durante un rato . \n",
      "예측문 :  tom y yo yo yo tambien estaba en la puerta . \n",
      "\n",
      "\n",
      "원문 :  would you like another apple ? \n",
      "번역문 : quieres otra manzana ? \n",
      "예측문 :  te gustaria otra vez ? \n",
      "\n",
      "\n",
      "원문 :  he eats lunch at a cafeteria . \n",
      "번역문 : el almuerza en una cafeteria . \n",
      "예측문 :  el como a un buen la manana . \n",
      "\n",
      "\n",
      "원문 :  don t change the channel . \n",
      "번역문 : no cambies de cadena . \n",
      "예측문 :  no en el ellos ? \n",
      "\n",
      "\n",
      "원문 :  tom traveled back in time . \n",
      "번역문 : tomas viajo al pasado . \n",
      "예측문 :  tom ha ido a tiempo . \n",
      "\n",
      "\n",
      "원문 :  tom is around thirty years old . \n",
      "번역문 : tom tiene alrededor de treinta anos . \n",
      "예측문 :  tom tiene que anos . \n",
      "\n",
      "\n",
      "원문 :  i went to bed at twelve last night . \n",
      "번역문 : anoche me fui a la cama a las doce . \n",
      "예측문 :  me fui a la noche a la cama en casa . \n",
      "\n",
      "\n",
      "원문 :  today i love the entire world . \n",
      "번역문 : hoy amo al mundo entero . \n",
      "예측문 :  hoy lo quiero el mundo todavia . \n",
      "\n",
      "\n",
      "원문 :  tie your shoelaces . \n",
      "번역문 : amarrate los cordones . \n",
      "예측문 :  ! hay un mano . \n",
      "\n",
      "\n",
      "원문 :  tom seems bored . \n",
      "번역문 : tom se ve aburrido . \n",
      "예측문 :  tom parece estar . \n",
      "\n",
      "\n",
      "원문 :  this is fascinating . \n",
      "번역문 : esto es fascinante . \n",
      "예측문 :  esto es es que queria . \n",
      "\n",
      "\n",
      "원문 :  why are you so worried ? \n",
      "번역문 : por que estan tan preocupadas ? \n",
      "예측문 :  por que estas tan esperando ? \n",
      "\n",
      "\n",
      "원문 :  tom is passed out in bed . \n",
      "번역문 : tom esta desmayado en la cama . \n",
      "예측문 :  tom se esta en la cama . \n",
      "\n",
      "\n",
      "원문 :  she didn t know what to say to him . \n",
      "번역문 : ella no sabia que decirle . \n",
      "예측문 :  no le queria a lo que . \n",
      "\n",
      "\n",
      "원문 :  it s the least i could do . \n",
      "번역문 : es lo menos que podia hacer . \n",
      "예측문 :  es lo que le paso a todo el tiempo . \n",
      "\n",
      "\n",
      "원문 :  he is very friendly to us . \n",
      "번역문 : el es muy amable con nosotras . \n",
      "예측문 :  el es muy esperando . \n",
      "\n",
      "\n",
      "원문 :  i m color blind . \n",
      "번역문 : soy daltonico . \n",
      "예측문 :  estoy haciendo el se de los . \n",
      "\n",
      "\n",
      "원문 :  nothing seemed out of the ordinary . \n",
      "번역문 : nada parecia fuera de lo ordinario . \n",
      "예측문 :  no habia nada que te hizo en la estado de los \n",
      "\n",
      "\n",
      "원문 :  i assumed you were hungry . \n",
      "번역문 : asumi que tenian hambre . \n",
      "예측문 :  yo en los que tenia hambre . \n",
      "\n",
      "\n",
      "원문 :  thanks in advance . \n",
      "번역문 : gracias por adelantado . \n",
      "예측문 :  gracias por el camino . \n",
      "\n",
      "\n",
      "원문 :  bacteria are invisible to the naked eye . \n",
      "번역문 : las bacterias son invisibles a simple vista . \n",
      "예측문 :  las que se me estan de fiesta ha sido el vida . \n",
      "\n",
      "\n",
      "원문 :  listen . \n",
      "번역문 : escucha . \n",
      "예측문 :  casi . \n",
      "\n",
      "\n",
      "원문 :  let s look on the positive side . \n",
      "번역문 : veamos el lado positivo . \n",
      "예측문 :  . \n",
      "\n",
      "\n",
      "원문 :  he still writes poems . \n",
      "번역문 : el todavia escribe poemas . \n",
      "예측문 :  todavia el estas palabra . \n",
      "\n",
      "\n",
      "원문 :  you re small . \n",
      "번역문 : eres pequeno . \n",
      "예측문 :  eres tu . \n",
      "\n",
      "\n",
      "원문 :  no one could answer my questions . \n",
      "번역문 : ninguno pudo responder mis preguntas . \n",
      "예측문 :  nadie puede que me mismo . \n",
      "\n",
      "\n",
      "원문 :  chemistry can be very complex . \n",
      "번역문 : la quimica puede ser muy compleja . \n",
      "예측문 :  la luz puede ser muy . \n",
      "\n",
      "\n",
      "원문 :  tom forgot to do his homework . \n",
      "번역문 : a tom se le olvido hacer los deberes . \n",
      "예측문 :  tom se me ha hecho con ver su los . \n",
      "\n",
      "\n",
      "원문 :  this river is deep enough to swim in . \n",
      "번역문 : este rio es suficientemente profundo para nadar . \n",
      "예측문 :  este padre el es demasiado que el esta sin leer . \n",
      "\n",
      "\n",
      "원문 :  i must be blind . \n",
      "번역문 : debo de estar ciego . \n",
      "예측문 :  tengo que estar . \n",
      "\n",
      "\n",
      "원문 :  this isn t a joke . \n",
      "번역문 : esto no es broma . \n",
      "예측문 :  no es una cosa . \n",
      "\n",
      "\n",
      "원문 :  tom got angry with mary . \n",
      "번역문 : tom se enojo con mary . \n",
      "예측문 :  tom se se le va con mary . \n",
      "\n",
      "\n",
      "원문 :  i need a cab . \n",
      "번역문 : necesito un taxi . \n",
      "예측문 :  necesito un minuto . \n",
      "\n",
      "\n",
      "원문 :  does anyone of you know them ? \n",
      "번역문 : alguna de ustedes los conoce ? \n",
      "예측문 :  alguien sabe que te ? \n",
      "\n",
      "\n",
      "원문 :  i gave in to her demands . \n",
      "번역문 : cedi a sus demandas . \n",
      "예측문 :  le yo . \n",
      "\n",
      "\n",
      "원문 :  the ice has melted . \n",
      "번역문 : el hielo se ha derretido . \n",
      "예측문 :  el perro se ha ido . \n",
      "\n",
      "\n",
      "원문 :  from now on you re one of us . \n",
      "번역문 : desde ahora eres uno de los nuestros . \n",
      "예측문 :  ahora de una la para que te ahora . \n",
      "\n",
      "\n",
      "원문 :  tom hopes to see you in october . \n",
      "번역문 : tom espera verte en octubre . \n",
      "예측문 :  tom espera que vi a dormir en un problema . \n",
      "\n",
      "\n",
      "원문 :  that s debatable . \n",
      "번역문 : eso es discutible . \n",
      "예측문 :  eso es . \n",
      "\n",
      "\n",
      "원문 :  the meeting was canceled . \n",
      "번역문 : la reunion fue cancelada . \n",
      "예측문 :  la reunion fue a la noche . \n",
      "\n",
      "\n",
      "원문 :  her kindness touched me . \n",
      "번역문 : su gentileza me conmovio . \n",
      "예측문 :  su me la vida . \n",
      "\n",
      "\n",
      "원문 :  i need to know where to put this . \n",
      "번역문 : necesito saber donde poner esto . \n",
      "예측문 :  necesito saber donde esta cosa . \n",
      "\n",
      "\n",
      "원문 :  you lost didn t you ? \n",
      "번역문 : perdiste verdad ? \n",
      "예측문 :  no te has perdido ? \n",
      "\n",
      "\n",
      "원문 :  tom knows he made a mistake . \n",
      "번역문 : tom sabe que cometio un error . \n",
      "예측문 :  tom sabe que lo hizo un error . \n",
      "\n",
      "\n",
      "원문 :  he made an apology to us for being late . \n",
      "번역문 : se disculpo con nosotros por haber llegado tarde . \n",
      "예측문 :  el le pidio que una tarde por una pregunta . \n",
      "\n",
      "\n",
      "원문 :  the bus was heading north . \n",
      "번역문 : el autobus se dirigia al norte . \n",
      "예측문 :  el autobus se fue de las grande . \n",
      "\n",
      "\n",
      "원문 :  are you home ? \n",
      "번역문 : estas en casa ? \n",
      "예측문 :  estas en casa ? \n",
      "\n",
      "\n",
      "원문 :  i have two cousins . \n",
      "번역문 : tengo dos primos . \n",
      "예측문 :  tengo dos . \n",
      "\n",
      "\n",
      "원문 :  you will conform . \n",
      "번역문 : te ajustaras a las normas establecidas . \n",
      "예측문 :  te lo esta . \n",
      "\n",
      "\n",
      "원문 :  tom is too stupid to be scared . \n",
      "번역문 : tom es demasiado estupido para asustarse . \n",
      "예측문 :  tom es demasiado joven para ser aqui . \n",
      "\n",
      "\n",
      "원문 :  have we met before ? \n",
      "번역문 : nos hemos encontrado antes ? \n",
      "예측문 :  nos has estado esperando eso ? \n",
      "\n",
      "\n",
      "원문 :  tom wasn t able to swim . \n",
      "번역문 : tom no fue capaz de nadar . \n",
      "예측문 :  tom no estaba tan rapido . \n",
      "\n",
      "\n",
      "원문 :  that was the best day of my life . \n",
      "번역문 : fue el mejor dia de mi vida . \n",
      "예측문 :  el es la mejor dia de mi vida . \n",
      "\n",
      "\n",
      "원문 :  somebody missed the dog . \n",
      "번역문 : alguien echaba de menos al perro . \n",
      "예측문 :  alguien ha perdido el perro . \n",
      "\n",
      "\n",
      "원문 :  the dog is barking . \n",
      "번역문 : el perro esta ladrando . \n",
      "예측문 :  el perro esta . \n",
      "\n",
      "\n",
      "원문 :  who wants this ? \n",
      "번역문 : quien quiere esto ? \n",
      "예측문 :  quien quiere esto ? \n",
      "\n",
      "\n",
      "원문 :  the tower leaned slightly to the west . \n",
      "번역문 : la torre estaba un poco inclinada hacia el oeste . \n",
      "예측문 :  la cansado de la nueva ido es un muy el hambre . \n",
      "\n",
      "\n",
      "원문 :  tom mounted his horse and rode off . \n",
      "번역문 : tom monto su caballo y se fue . \n",
      "예측문 :  tom se fue a su caja y yo el ano . \n",
      "\n",
      "\n",
      "원문 :  my mother set the table for dinner . \n",
      "번역문 : mi madre puso la mesa para la cena . \n",
      "예측문 :  mi madre le ha mesa a la noche . \n",
      "\n",
      "\n",
      "원문 :  tom will regret this . \n",
      "번역문 : tom va a lamentarlo . \n",
      "예측문 :  tom lo esta . \n",
      "\n",
      "\n",
      "원문 :  tom shot her . \n",
      "번역문 : tomas le disparo . \n",
      "예측문 :  tom le dio la mano . \n",
      "\n",
      "\n",
      "원문 :  he was born and raised in tokyo . \n",
      "번역문 : nacio y crecio en tokio . \n",
      "예측문 :  el fue en la cama y un poco mas . \n",
      "\n",
      "\n",
      "원문 :  we pretty much gave up hope . \n",
      "번역문 : casi perdimos la esperanza . \n",
      "예측문 :  nos dio un monton de este mano . \n",
      "\n",
      "\n",
      "원문 :  tom wanted to become a canadian citizen . \n",
      "번역문 : tom queria convertirse en ciudadano canadiense . \n",
      "예측문 :  tom queria ser canadiense que ella se . \n",
      "\n",
      "\n",
      "원문 :  i may be old but i m not crazy . \n",
      "번역문 : puede que sea viejo pero no estoy loco . \n",
      "예측문 :  puedo que sea muy que me puede ser su . \n",
      "\n",
      "\n",
      "원문 :  i feel as if i were dreaming . \n",
      "번역문 : me siento como si estuviera sonando . \n",
      "예측문 :  me siento como si estaba noche . \n",
      "\n",
      "\n",
      "원문 :  let s not be too hasty . \n",
      "번역문 : no seamos demasiado imprudentes . \n",
      "예측문 :  no vamos muy hecho . \n",
      "\n",
      "\n",
      "원문 :  you re first . \n",
      "번역문 : tu eres el primero . \n",
      "예측문 :  tu eres el . \n",
      "\n",
      "\n",
      "원문 :  all is still . \n",
      "번역문 : todo esta en calma . \n",
      "예측문 :  todo el mundo . \n",
      "\n",
      "\n",
      "원문 :  no one will know i m here . \n",
      "번역문 : nadie sabra que estoy aqui . \n",
      "예측문 :  nadie sabe aqui para mi . \n",
      "\n",
      "\n",
      "원문 :  do you hear something ? \n",
      "번역문 : ois algo ? \n",
      "예측문 :  has algo de lo que ? \n",
      "\n",
      "\n",
      "원문 :  you re the only one who can help me . \n",
      "번역문 : eres el unico que puede ayudarme . \n",
      "예측문 :  eres la misma casa que yo yo solo . \n",
      "\n",
      "\n",
      "원문 :  i said i would tell you . \n",
      "번역문 : dije que te lo contaria . \n",
      "예측문 :  dije que te lo que . \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  you should not wear a fur coat . \n",
      "번역문 : no deberias llevar un abrigo de piel . \n",
      "예측문 :  no deberias un ojos para mi solo . \n",
      "\n",
      "\n",
      "원문 :  i arrived later than usual . \n",
      "번역문 : yo llegue mas tarde de lo acostumbrado . \n",
      "예측문 :  me siento mas tarde . \n",
      "\n",
      "\n",
      "원문 :  listen to this . \n",
      "번역문 : escuche esto . \n",
      "예측문 :  esto en una decision . \n",
      "\n",
      "\n",
      "원문 :  she seems to get fatter and fatter . \n",
      "번역문 : parece estar poniendose cada vez mas gorda . \n",
      "예측문 :  parece que tiene que estar en casa demasiado r\n",
      "\n",
      "\n",
      "원문 :  i wrote you three letters . \n",
      "번역문 : te escribi tres cartas . \n",
      "예측문 :  te vi a un poco para el tiempo . \n",
      "\n",
      "\n",
      "원문 :  how many hours are left ? \n",
      "번역문 : cuantas horas faltan ? \n",
      "예측문 :  cuantos horas ? \n",
      "\n",
      "\n",
      "원문 :  he usually comes in time . \n",
      "번역문 : el normalmente viene puntual . \n",
      "예측문 :  el tiempo para la hora . \n",
      "\n",
      "\n",
      "원문 :  all right . i ll accept your offer . \n",
      "번역문 : de acuerdo . acepto tu oferta . \n",
      "예측문 :  todo el mundo es idea de que se va a dar un buen d\n",
      "\n",
      "\n",
      "원문 :  tom shouldn t have made mary angry . \n",
      "번역문 : tom no debio haber hecho enfadar a mary . \n",
      "예측문 :  tom no deberia haber hecho con mary . \n",
      "\n",
      "\n",
      "원문 :  tom is snoring . \n",
      "번역문 : tom esta roncando . \n",
      "예측문 :  tom esta yo . \n",
      "\n",
      "\n",
      "원문 :  nod your head if you understand . \n",
      "번역문 : inclina tu cabeza si me entiendes . \n",
      "예측문 :  . te has hecho el de la cabeza . \n",
      "\n",
      "\n",
      "원문 :  you missed . \n",
      "번역문 : fallaste . \n",
      "예측문 :  te ha perdido . \n",
      "\n",
      "\n",
      "원문 :  she quickly opened the letter . \n",
      "번역문 : abrio la carta rapidamente . \n",
      "예측문 :  ella esta una carta se quedo rapido . \n",
      "\n",
      "\n",
      "원문 :  tom spilled ink on the desk . \n",
      "번역문 : tom volco la tinta sobre el escritorio . \n",
      "예측문 :  tom sobre la mesa no esta rapido . \n",
      "\n",
      "\n",
      "원문 :  i like art . \n",
      "번역문 : me gusta el arte . \n",
      "예측문 :  me gusta el entiendo . \n",
      "\n",
      "\n",
      "원문 :  i am unable to agree on that point . \n",
      "번역문 : no puedo estar de acuerdo en este punto . \n",
      "예측문 :  estoy seguro de que no es en problemas . \n",
      "\n",
      "\n",
      "원문 :  keep it in mind . \n",
      "번역문 : tenedlo presente . \n",
      "예측문 :  en lo . \n",
      "\n",
      "\n",
      "원문 :  how do you manage to do this ? \n",
      "번역문 : como se maneja usted para hacer esto ? \n",
      "예측문 :  como hacer esto para que te ? \n",
      "\n",
      "\n",
      "원문 :  this book is hard for me to read . \n",
      "번역문 : para mi este libro es dificil de leer . \n",
      "예측문 :  este libro es mejor para mi no . \n",
      "\n",
      "\n",
      "원문 :  i will never forgive you . \n",
      "번역문 : nunca te perdonare . \n",
      "예측문 :  nunca te lo . \n",
      "\n",
      "\n",
      "원문 :  i have no ear for music . \n",
      "번역문 : no tengo oido para la musica . \n",
      "예측문 :  no tengo la musica para el . \n",
      "\n",
      "\n",
      "원문 :  seize him ! \n",
      "번역문 : cogedlo ! \n",
      "예측문 :  ! \n",
      "\n",
      "\n",
      "원문 :  how was your trip ? \n",
      "번역문 : como estuvo tu viaje ? \n",
      "예측문 :  como estaba tu tiempo ? \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "  print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "  print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "  print(\"예측문 :\",decoded_sentence[:-5])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
