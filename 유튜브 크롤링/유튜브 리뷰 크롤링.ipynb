{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인기영상 크롤링\n",
    "- 주제에 관계없이 가장 많은 리뷰를 뽑아쓸 수 있는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trending_video():\n",
    "    url = 'https://www.youtube.com/feed/trending'\n",
    "\n",
    "    driver = webdriver.Chrome('./chromedriver') #크롬 드라이버 경로\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "        time.sleep(5)\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height:\n",
    "            break\n",
    "\n",
    "        last_page_height = new_page_height\n",
    "\n",
    "    \n",
    "    load_box = driver.find_elements_by_css_selector('#grid-container ytd-video-renderer')\n",
    "    \n",
    "    info_dict = {'title' : [],\n",
    "                'link' : [],\n",
    "                'Youtuber' : [],\n",
    "                'view' : [],\n",
    "                'date' : []}\n",
    "    for video in load_box:\n",
    "        \n",
    "        #제목\n",
    "        title = video.find_element_by_css_selector('#video-title').text\n",
    "        #url\n",
    "        link = video.find_element_by_css_selector('#video-title').get_attribute('href')\n",
    "        #유튜버\n",
    "        Youtuber = video.find_element_by_css_selector('#text a').text\n",
    "        #조회수\n",
    "        view = video.find_element_by_css_selector('#metadata-line span:nth-child(1)').text\n",
    "        #날짜\n",
    "        date = video.find_element_by_css_selector('#metadata-line span:nth-child(2)').text\n",
    "        \n",
    "        info_dict['title'].append(title)\n",
    "        info_dict['link'].append(link)\n",
    "        info_dict['Youtuber'].append(Youtuber)\n",
    "        info_dict['view'].append(view)\n",
    "        info_dict['date'].append(date)\n",
    "\n",
    "    df = pd.DataFrame(info_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_trending_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장할때 날짜정보 저장해서, 하루 전 데이터를 불러오고 url비교해서 크롤링할 url이랑 아닌거랑 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력어 받는 파이썬파일로.  \n",
    "원하는리뷰수를 인풋?  \n",
    "-이거계산하는거만들어보고  \n",
    "url도 인풋으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스크롤 횟수\n",
    "\n",
    "def Youtube_crawl(url, scroll_cnt):\n",
    "    scroll_cnt = scroll_cnt\n",
    "\n",
    "    url = url\n",
    "\n",
    "    #자신의 크롬 버전에 맞는 드라이버 다운\n",
    "    driver = webdriver.Chrome('./chromedriver') #크롬 드라이버 경로\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(2) #댓글창로딩\n",
    "\n",
    "    body = driver.find_element_by_tag_name('body')\n",
    "\n",
    "    while scroll_cnt:\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1)\n",
    "        scroll_cnt -= 1\n",
    "\n",
    "    reviews = driver.find_elements_by_xpath('//*[@id=\"main\"]')\n",
    "    likes = driver.find_elements_by_xpath('//*[@id=\"vote-count-middle\"]')\n",
    "    print(scroll_cnt, len(reviews))\n",
    "\n",
    "\n",
    "    if len(reviews) != len(likes):\n",
    "        reviews = reviews[:-1] #마지막 review에 Youtube Premium 광고가 섞이는경우가있음\n",
    "\n",
    "    df = pd.DataFrame(columns=['리뷰', '좋아요'])\n",
    "\n",
    "    review_list = []\n",
    "    like_list = []\n",
    "    for review, like in zip(reviews, likes):\n",
    "        review_list.append(review.text)\n",
    "        like_list.append(like.text)\n",
    "\n",
    "    df['리뷰'] = review_list\n",
    "    df['좋아요'] = like_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### page_down을 사용하면 버벅거리기에 느리다.\n",
    "- page_down 대신에 scrollHeight 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Youtube_crawl_2(url):\n",
    "    url = url\n",
    "\n",
    "    #자신의 크롬 버전에 맞는 드라이버 다운\n",
    "    driver = webdriver.Chrome('./chromedriver') #크롬 드라이버 경로\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5) #댓글창로딩\n",
    "\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    #댓글 최하단까지 이동\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "        time.sleep(5)\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height:\n",
    "            break\n",
    "\n",
    "        last_page_height = new_page_height\n",
    "    \n",
    "    #자세히 보기를 클릭해 리뷰 잘림 현상 방지\n",
    "    load_more = driver.find_elements_by_xpath('//*[@id=\"more\"]/span')\n",
    "\n",
    "    for load in load_more:\n",
    "        if load.text == '자세히 보기':\n",
    "            load.click()\n",
    "\n",
    "    reviews = driver.find_elements_by_xpath('//*[@id=\"main\"]')\n",
    "    likes = driver.find_elements_by_xpath('//*[@id=\"vote-count-middle\"]')\n",
    "\n",
    "    if len(reviews) != len(likes):\n",
    "        reviews = reviews[:-1] #마지막 review에 Youtube Premium 광고가 섞이는경우가있음\n",
    "\n",
    "    df = pd.DataFrame(columns=['리뷰', '좋아요'])\n",
    "\n",
    "    review_list = []\n",
    "    like_list = []\n",
    "    for review, like in zip(reviews, likes):\n",
    "        review_list.append(review.text)\n",
    "        like_list.append(like.text)\n",
    "\n",
    "    df['리뷰'] = review_list\n",
    "    df['좋아요'] = like_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 답글이 있는 댓글을 못가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Youtube_crawl_3(url):\n",
    "    url = url\n",
    "\n",
    "    #자신의 크롬 버전에 맞는 드라이버 다운\n",
    "    driver = webdriver.Chrome('./chromedriver') #크롬 드라이버 경로\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5) #댓글창로딩\n",
    "\n",
    "    #모든 댓글 불러오기\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "        time.sleep(5)\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height:\n",
    "            break\n",
    "\n",
    "        last_page_height = new_page_height\n",
    "    \n",
    "    #대댓글 불러오기\n",
    "    load_reply = driver.find_elements_by_css_selector('#contents #text')\n",
    "\n",
    "    for load in load_reply:\n",
    "        #답글을 남기는 '답글' 과 '답글 n개 보기' 중 'n개 보기' 필터링\n",
    "        if '보기' in load.text: \n",
    "            driver.execute_script('arguments[0].click();',load)\n",
    "            #load.click()의 경우 오류가 발생\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    #대댓글 더 불러오기\n",
    "    while True:\n",
    "        try:\n",
    "            check_point = driver.find_elements_by_xpath('//*[@id=\"continuation\"]/yt-next-continuation/paper-button/yt-formatted-string')\n",
    "\n",
    "            if len(check_point):\n",
    "                #답글이 일정 수준을 넘기면 '답글 더보기'가 등장, 이를 클릭하기 위함\n",
    "                load_more_reply = driver.find_elements_by_xpath('//*[@id=\"continuation\"]/yt-next-continuation/paper-button/yt-formatted-string')\n",
    "\n",
    "                for load in load_more_reply:\n",
    "                    driver.execute_script('arguments[0].click();',load)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    \n",
    "    #답글에도 자세히보기를 사용해야할경우가있기때문에 자세히보기 클릭은 답글을 다 연 다음에\n",
    "    load_detail = driver.find_elements_by_xpath('//*[@id=\"more\"]/span')\n",
    "\n",
    "    for load in load_detail:\n",
    "        if load.text == '자세히 보기':\n",
    "            driver.execute_script('arguments[0].click();',load)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    reviews = driver.find_elements_by_css_selector('#content-text')\n",
    "    likes = driver.find_elements_by_xpath('//*[@id=\"vote-count-middle\"]')\n",
    "\n",
    "    if len(reviews) != len(likes):\n",
    "        reviews = reviews[:-1] #마지막 review에 Youtube Premium 광고가 섞이는경우가있음\n",
    "\n",
    "    df = pd.DataFrame(columns=['리뷰', '좋아요'])\n",
    "\n",
    "    review_list = []\n",
    "    like_list = []\n",
    "    for review, like in zip(reviews, likes):\n",
    "        review_list.append(review.text)\n",
    "        like_list.append(like.text)\n",
    "\n",
    "    df['리뷰'] = review_list\n",
    "    df['좋아요'] = like_list\n",
    "    \n",
    "    #좋아요 전처리\n",
    "    df['좋아요'] = df['좋아요'].apply(lambda x: re.sub('천 | 만','000',x)) #천의 경우는 1천 / 만의 경우는 1.1만 의 경우로 표현됨\n",
    "    \n",
    "    #좋아요가 없는 칼럼은 1로 대체\n",
    "    indexes = df[df['좋아요'] == ''].index\n",
    "    df.loc[indexes, '좋아요'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube_crawl_3의 경우 리뷰와 좋아요를 따로 뽑고 하나로 합치는 방식이기에, 좋아요와 리뷰의 순서가 맞지 않을 가능성 발생\n",
    "따라서 각 리뷰가 담긴 박스 전체를 추출하고, 그 안에서 ID, 리뷰, 좋아요, 날짜를 추출하는 방식으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Youtube_crawl_4(url):\n",
    "    url = url\n",
    "\n",
    "    #자신의 크롬 버전에 맞는 드라이버 다운\n",
    "    driver = webdriver.Chrome('./chromedriver') #크롬 드라이버 경로\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5) #댓글창로딩\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    #모든 댓글 불러오기\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "        time.sleep(5)\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height:\n",
    "            break\n",
    "\n",
    "        last_page_height = new_page_height\n",
    "\n",
    "    #대댓글 불러오기\n",
    "    load_reply = driver.find_elements_by_css_selector('#contents #text')\n",
    "\n",
    "    for load in load_reply:\n",
    "        #답글을 남기는 '답글' 과 '답글 n개 보기' 중 'n개 보기' 필터링\n",
    "        if '보기' in load.text: \n",
    "            driver.execute_script('arguments[0].click();',load)\n",
    "            #load.click()의 경우 오류가 발생\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #대댓글 더 불러오기\n",
    "    while True:\n",
    "        try:\n",
    "            check_point = driver.find_elements_by_xpath('//*[@id=\"continuation\"]/yt-next-continuation/paper-button/yt-formatted-string')\n",
    "\n",
    "            if len(check_point):\n",
    "                #답글이 일정 수준을 넘기면 '답글 더보기'가 등장, 이를 클릭하기 위함\n",
    "                load_more_reply = driver.find_elements_by_xpath('//*[@id=\"continuation\"]/yt-next-continuation/paper-button/yt-formatted-string')\n",
    "\n",
    "                for load in load_more_reply:\n",
    "                    driver.execute_script('arguments[0].click();',load)\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    load_content = driver.find_elements_by_xpath('//*[@id=\"main\"]')\n",
    "\n",
    "    content_info = {'author':[],\n",
    "                   'date' : [],\n",
    "                   'review' : [],\n",
    "                   'like' : []}\n",
    "  \n",
    "    for content in load_content:\n",
    "        try: #Youtube Premium이 걸릴경우가 있다\n",
    "            #ID\n",
    "            author = content.find_element_by_css_selector('#author-text span').text\n",
    "            #날짜\n",
    "            date = content.find_element_by_css_selector('#header-author  yt-formatted-string  a').text\n",
    "            #리뷰\n",
    "            review = content.find_element_by_css_selector('#content-text').text\n",
    "            #like\n",
    "            like = content.find_element_by_css_selector('#vote-count-middle').text\n",
    "\n",
    "            content_info['author'].append(author)\n",
    "            content_info['date'].append(date)\n",
    "            content_info['review'].append(review)\n",
    "            content_info['like'].append(like)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame(content_info)\n",
    "\n",
    "    #like 전처리\n",
    "    df['like'] = df['like'].apply(lambda x: re.sub('천 | 만','000',x)) #천의 경우는 1천 / 만의 경우는 1.1만 의 경우로 표현됨\n",
    "\n",
    "    #like가 없는 칼럼은 1로 대체\n",
    "    indexes = df[df['like'] == ''].index\n",
    "    df.loc[indexes, 'like'] = 1\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print('time: {}'.format(end-start))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>달님</td>\n",
       "      <td>1일 전</td>\n",
       "      <td>인터스텔라에서 최강의 트롤링을 보여주던 그는 화성에서 살아남기를 찍습니다</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>테루시아</td>\n",
       "      <td>1일 전</td>\n",
       "      <td>아빠죽이려한 만박사를\\n어떻게든 구하는 머피</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BenYa Entertainment</td>\n",
       "      <td>1일 전</td>\n",
       "      <td>아 그러고보니 배우가....ㄷㄷ</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>코끼리</td>\n",
       "      <td>17시간 전(수정됨)</td>\n",
       "      <td>우주선에는 캡틴아메리카의 친구와 앤트맨의 친구가 있어서 든든\\n나사에서는 닥터스트레...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>창호</td>\n",
       "      <td>3시간 전</td>\n",
       "      <td>맞네 ㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>조원태</td>\n",
       "      <td>1일 전</td>\n",
       "      <td>저도 다른 결말포함 리뷰어들이 많이 올린 영화는 안 올려주셨으면 하네요</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>이시형</td>\n",
       "      <td>23시간 전</td>\n",
       "      <td>@이시경 @ㅐ미없는소리하네 ㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>이시경</td>\n",
       "      <td>22시간 전</td>\n",
       "      <td>야야 미안하다 ㅋㅋ 앞으로는 생각하고 글 싸지를게</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>몽초코</td>\n",
       "      <td>18시간 전</td>\n",
       "      <td>@이시경 여러사람한테 욕처먹지 않았으면 넌 그대로였을거아냐 그치? 너같은애들은 변할...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>이시경</td>\n",
       "      <td>18시간 전(수정됨)</td>\n",
       "      <td>@몽초코 어....그래 미안해 기분나빴으면 미안하다 ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author         date  \\\n",
       "0                     달님         1일 전   \n",
       "1                   테루시아         1일 전   \n",
       "2    BenYa Entertainment         1일 전   \n",
       "3                    코끼리  17시간 전(수정됨)   \n",
       "4                     창호        3시간 전   \n",
       "..                   ...          ...   \n",
       "185                  조원태         1일 전   \n",
       "186                  이시형       23시간 전   \n",
       "187                  이시경       22시간 전   \n",
       "188                  몽초코       18시간 전   \n",
       "189                  이시경  18시간 전(수정됨)   \n",
       "\n",
       "                                                review like  \n",
       "0             인터스텔라에서 최강의 트롤링을 보여주던 그는 화성에서 살아남기를 찍습니다  127  \n",
       "1                             아빠죽이려한 만박사를\\n어떻게든 구하는 머피  105  \n",
       "2                                    아 그러고보니 배우가....ㄷㄷ    6  \n",
       "3    우주선에는 캡틴아메리카의 친구와 앤트맨의 친구가 있어서 든든\\n나사에서는 닥터스트레...    2  \n",
       "4                                               맞네 ㅋㅋㅋ    1  \n",
       "..                                                 ...  ...  \n",
       "185            저도 다른 결말포함 리뷰어들이 많이 올린 영화는 안 올려주셨으면 하네요    3  \n",
       "186                                 @이시경 @ㅐ미없는소리하네 ㅋㅋㅋ    1  \n",
       "187                        야야 미안하다 ㅋㅋ 앞으로는 생각하고 글 싸지를게    1  \n",
       "188  @이시경 여러사람한테 욕처먹지 않았으면 넌 그대로였을거아냐 그치? 너같은애들은 변할...    1  \n",
       "189                    @몽초코 어....그래 미안해 기분나빴으면 미안하다 ㅋㅋ    1  \n",
       "\n",
       "[190 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Youtube_crawl_4('https://www.youtube.com/watch?v=xwhhAkz-wFk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대댓글은 영상의 주제와 관계 없이, 리뷰를 남긴 사람에 집중하는 경우가 많다. ex) 서로를 물어뜯거나, 찐이다 등등\n",
    "따라서 해당 주제에 대한 긍정/부정을 파악하는데에 오히려 도움이 되지 않는다고 판단, 대댓글을 불러오지 않는 크롤러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Youtube_crawl_without_coco(url):\n",
    "    url = url\n",
    "\n",
    "    #자신의 크롬 버전에 맞는 드라이버 다운\n",
    "    driver = webdriver.Chrome('./chromedriver') #크롬 드라이버 경로\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5) #댓글창로딩\n",
    "\n",
    "    #모든 댓글 불러오기\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight)\")\n",
    "        time.sleep(5)\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height:\n",
    "            break\n",
    "\n",
    "        last_page_height = new_page_height\n",
    "    \n",
    "    \n",
    "    #답글에도 자세히보기를 사용해야할경우가있기때문에 자세히보기 클릭은 답글을 다 연 다음에\n",
    "    load_detail = driver.find_elements_by_xpath('//*[@id=\"more\"]/span')\n",
    "\n",
    "    for load in load_detail:\n",
    "        if load.text == '자세히 보기':\n",
    "            driver.execute_script('arguments[0].click();',load)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    load_content = driver.find_elements_by_xpath('//*[@id=\"main\"]')\n",
    "\n",
    "    content_info = {\n",
    "#                     'video_title' : [],\n",
    "#                     'video_view' : [],\n",
    "#                     'Youtuber': [],\n",
    "#                     'video_date' : [],\n",
    "                    'author':[],\n",
    "                    'date' : [],\n",
    "                    'review' : [],\n",
    "                    'like' : []}\n",
    "    \n",
    "    for content in load_content:\n",
    "        #ID\n",
    "        author = content.find_element_by_css_selector('#author-text span').text\n",
    "        #날짜\n",
    "        date = content.find_element_by_css_selector('#header-author  yt-formatted-string  a').text\n",
    "        #리뷰\n",
    "        review = content.find_element_by_css_selector('#content-text').text\n",
    "        #like\n",
    "        like = content.find_element_by_css_selector('#vote-count-middle').text\n",
    "\n",
    "        content_info['author'].append(author)\n",
    "        content_info['date'].append(date)\n",
    "        content_info['review'].append(review)\n",
    "        content_info['like'].append(like)\n",
    "\n",
    "    df = pd.DataFrame(content_info)\n",
    "    \n",
    "#         #title\n",
    "#     df['video_title'] = driver.find_element_by_css_selector('#container > h1 > yt-formatted-string').text\n",
    "\n",
    "#     #view_count\n",
    "#     df['video_view'] = driver.find_element_by_css_selector('#count > yt-view-count-renderer > span.view-count.style-scope.yt-view-count-renderer').text\n",
    "\n",
    "#     #Youtuber\n",
    "#     df['Youtuber'] = driver.find_element_by_css_selector('#text > a').text\n",
    "\n",
    "#     #date\n",
    "#     df['date'] = driver.find_element_by_css_selector('#date > yt-formatted-string').text\n",
    "\n",
    "#     #like 전처리\n",
    "#     df['like'] = df['like'].apply(lambda x: re.sub('천 | 만','000',x)) #천의 경우는 1천 / 만의 경우는 1.1만 의 경우로 표현됨\n",
    "\n",
    "    #like가 없는 칼럼은 1로 대체\n",
    "    indexes = df[df['like'] == ''].index\n",
    "    df.loc[indexes, 'like'] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-3082ba95422f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYoutube_crawl_without_coco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.youtube.com/watch?v=HhgcXuN0MlU&t=599s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# df.to_pickle('유튜브 리뷰 댓글제거.pkl')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-100-ad2f3e7be8bd>\u001b[0m in \u001b[0;36mYoutube_crawl_without_coco\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mcontent_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'like'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m#title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "df = Youtube_crawl_without_coco('https://www.youtube.com/watch?v=HhgcXuN0MlU&t=599s')\n",
    "df.to_pickle('유튜브 리뷰 댓글제거.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보다 많은 리뷰가 성공적으로 불러와졌다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "reviews = driver.find_elements_by_xpath('//*[@id=\"main\"]')\n",
    "reviews = driver.find_elements_by_css_selector('#content-text')\n",
    "\n",
    "---\n",
    "xpath로 가져오는 데이터와 css_selector로 가져오는 데이터가 서로 다르다\n",
    "xpath, css_selector로 가져왔을 때 뭔가 불만족스럽다면 서로를 바꿔보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 좋아요 수 전처리\n",
    "- '1천', or ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "답글과 자세히보기문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "like에 가중치를 둔다면?\n",
    "댓글 * like로 가중치를두어계산(이때 log2 씌워주고) #like가없다면 차이를두어야겠지?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
